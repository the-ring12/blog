<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://the_ring.gitee.io/blog/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/blog/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/blog/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/blog/css/style.css">

  
    
<link rel="stylesheet" href="/blog/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 6.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/blog/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/blog/">Home</a>
        
          <a class="main-nav-link" href="/blog/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/blog/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://the_ring.gitee.io/blog"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-从 Kafka 到 Pulsar：数据流演进之路" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/blog/2022/08/26/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/" class="article-date">
  <time class="dt-published" datetime="2022-08-26T00:13:40.000Z" itemprop="datePublished">2022-08-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/blog/2022/08/26/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/">从 Kafka 到 Pulsar：数据流演进之路</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-消息队列概述"><a href="#1-消息队列概述" class="headerlink" title="1. 消息队列概述"></a>1. 消息队列概述</h2><p>消息队列应用场景：</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826081846927.png" alt="image-20220826081846927"></p>
<p>MQ 消息通道</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826081931112.png" alt="image-20220826081931112"></p>
<p>EventBridge 数据总线</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826082058618.png" alt="image-20220826082058618"></p>
<p>Data Platform 流数据平台</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826082143062.png" alt="image-20220826082143062"></p>
<p>主流消息队列的相关介绍</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826082216956.png" alt="image-20220826082216956"></p>
<h2 id="2-Kafka-详解"><a href="#2-Kafka-详解" class="headerlink" title="2. Kafka 详解"></a>2. Kafka 详解</h2><p>Kafka 架构</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826082429994.png" alt="image-20220826082429994"></p>
<p>Zookeeper</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826082552234.png" alt="image-20220826082552234"></p>
<p>Broker</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826082801645.png" alt="image-20220826082801645"></p>
<p>Controller 选举</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826082836650.png" alt="image-20220826082836650"></p>
<p>Controller 作用</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826083018970.png" alt="image-20220826083018970"></p>
<p>Coordinator</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826083200971.png" alt="image-20220826083200971"></p>
<p>Kafka 高可用</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826083224066.png" alt="image-20220826083224066"></p>
<p>Kakfa 副本 ISR 机制</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826083333156.png" alt="image-20220826083333156"></p>
<p>Kafka 写入 Ack 机制</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826083450698.png" alt="image-20220826083450698"></p>
<p>Kafka 副本同步</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826083807358.png" alt="image-20220826083807358"></p>
<p>Kafka 副本选举</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826084050414.png" alt="image-20220826084050414"></p>
<p>Kafka 集群扩缩容</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826084259569.png" alt="image-20220826084259569"></p>
<p>Kafka 扩容步骤</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826084407068.png" alt="image-20220826084407068"></p>
<p>Kafka 集群缩容步骤</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826084435833.png" alt="image-20220826084435833"></p>
<p>Kafka 集群扩缩容问题</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826084458218.png" alt="image-20220826084458218"></p>
<p>Kafka 未来演进之路</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826084603831.png" alt="image-20220826084603831"></p>
<p>Kafka 去除 zk 依赖</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826084634277.png" alt="image-20220826084634277"></p>
<p>Kafka 依赖 KRaft</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826084821259.png" alt="image-20220826084821259"></p>
<p>Kafka 运维&#x2F;调优经验介绍</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826084942171.png" alt="image-20220826084942171"></p>
<p>Kafka 单机吞吐</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826085017583.png" alt="image-20220826085017583"></p>
<p>Kafka 集群参数配置</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826085050863.png" alt="image-20220826085050863"></p>
<p>扩缩容优化</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826085219847.png" alt="image-20220826085219847"></p>
<p>指标可视化</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826085241757.png" alt="image-20220826085241757"></p>
<h2 id="3-Pulsar-详解"><a href="#3-Pulsar-详解" class="headerlink" title="3. Pulsar 详解"></a>3. Pulsar 详解</h2><p>Pulsar 结构介绍</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826085422457.png" alt="image-20220826085422457"></p>
<p>Pulsar Proxy</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826085520313.png" alt="image-20220826085520313"></p>
<p>Pulsar Broker</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826085613533.png" alt="image-20220826085613533"></p>
<p>Pulsar Storage</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826085729113.png" alt="image-20220826085729113"></p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826085837615.png" alt="image-20220826085837615"></p>
<p>Pulsar IO 连接器</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826085958609.png" alt="image-20220826085958609"></p>
<p>Pulsar Function（轻量级计算框架）</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826090031169.png" alt="image-20220826090031169"></p>
<p>Bookkeeper 介绍</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826090043371.png" alt="image-20220826090043371"></p>
<p>Bookkeeper 基本概念</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826090240874.png" alt="image-20220826090240874"></p>
<p>Bookkeeper 新建 Leader</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826090304726.png" alt="image-20220826090304726"></p>
<p>Bookeeper Ledger 分布</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826090511043.png" alt="image-20220826090511043"></p>
<p>Bookkeeper 写一致性</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826090620965.png" alt="image-20220826090620965"></p>
<p>Bookkper 读一致性</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826090814843.png" alt="image-20220826090814843"></p>
<p>Bookkeeper with pulsar</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826090904279.png" alt="image-20220826090904279"></p>
<p>Pulsar 功能介绍</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826090924186.png" alt="image-20220826090924186"></p>
<p>Pulsar 生产模式</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826091020338.png" alt="image-20220826091020338"></p>
<p>Pulsar 消费模式</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826091109837.png" alt="image-20220826091109837"></p>
<p>Exclusive 消费模式</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826091121633.png" alt="image-20220826091121633"></p>
<p>Failobver 消费模式</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826091140765.png" alt="image-20220826091140765"></p>
<p>Shared 消费模式</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826091155205.png" alt="image-20220826091155205"></p>
<p>Key-Shared 消费模式</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826091215900.png" alt="image-20220826091215900"></p>
<p>Pulsar 多租户</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826091242129.png" alt="image-20220826091242129"></p>
<p>Pulsar Plugin</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826091344623.png" alt="image-20220826091344623"></p>
<p>Pulsar GEO Relication</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826091438256.png" alt="image-20220826091438256"></p>
<p>Pulsar HA &amp; Scale-up</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826091521124.png" alt="image-20220826091521124"></p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826091612541.png" alt="image-20220826091612541"></p>
<p>Pulsar vs kafka</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826091630287.png" alt="image-20220826091630287"></p>
<p>存储计算分离</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826091727747.png" alt="image-20220826091727747"></p>
<h2 id="4-周边和生态"><a href="#4-周边和生态" class="headerlink" title="4. 周边和生态"></a>4. 周边和生态</h2><p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826091840592.png" alt="image-20220826091840592"></p>
<p>Pulsar IO</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826091938946.png" alt="image-20220826091938946"></p>
<p>Kafka Schema</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826091957389.png" alt="image-20220826091957389"></p>
<p>Pulsar SQL</p>
<p><img src="/blog/images/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/image-20220826092033507.png" alt="image-20220826092033507"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://the_ring.gitee.io/blog/2022/08/26/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/" data-id="cl79sj7gp0007zgut85dq15on" data-title="从 Kafka 到 Pulsar：数据流演进之路" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Kafka/" rel="tag">Kafka</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Pulsar/" rel="tag">Pulsar</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/big-data/" rel="tag">big data</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-深入浅出 HBase 实战" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/blog/2022/08/09/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%20HBase%20%E5%AE%9E%E6%88%98/" class="article-date">
  <time class="dt-published" datetime="2022-08-09T02:41:20.000Z" itemprop="datePublished">2022-08-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/blog/2022/08/09/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%20HBase%20%E5%AE%9E%E6%88%98/">深入浅出 HBase 实战</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-适用场景"><a href="#1-适用场景" class="headerlink" title="1. 适用场景"></a>1. 适用场景</h2><p>HBase 是一个开源的 NoSQL 分布式数据库，是 Apache 软件基金会顶级项目之一。</p>
<p>参考 Google Big Table 的设计，对稀疏表提供更高的存储空间适用率和读写效率。</p>
<p>采用存储计算分离结构</p>
<ul>
<li>存储层基于 HDFS 存储数据，提供容错机制和高可靠性；</li>
<li>计算曾提供灵活快速的水平扩展、负载均衡和故障恢复能力。</li>
</ul>
<p>提供强一致语义，在 CAP 理论中属于 CP 系统。</p>
<table>
<thead>
<tr>
<th align="center">-</th>
<th align="center">HBase</th>
<th align="center">Relational DB</th>
</tr>
</thead>
<tbody><tr>
<td align="center">数据结构</td>
<td align="center">半结构化，无数据类型；<br>按列族稀疏存储，缺省数据不占用存储空间；<br>支持多版本数据；</td>
<td align="center">结构化，数据类型丰富；<br>按完整行存储，缺省的列需要存储占位符；<br>不支持多版本数据</td>
</tr>
<tr>
<td align="center">读写模式</td>
<td align="center">支持按需读写部分列</td>
<td align="center">必须整行读取</td>
</tr>
<tr>
<td align="center">事务支持</td>
<td align="center">仅支持单行内原子性</td>
<td align="center">支持完整的事务语义</td>
</tr>
<tr>
<td align="center">数据规模</td>
<td align="center">适用于 TB、PB 级海量数据，水平扩展快速平滑</td>
<td align="center">仅适用于 GB、小量 TB 、级，扩展过程较复杂</td>
</tr>
<tr>
<td align="center">索引支持</td>
<td align="center">仅支持 rowkey 主键索引</td>
<td align="center">支持二级索引</td>
</tr>
</tbody></table>
<p>HBase 以列族组织数据，义行键索引数据。</p>
<ul>
<li>列族需要在使用前预先创建，列名不需要预先声明，因此支持半结构化数据类型。</li>
<li>支持保留多个版本的数据，（行键 + 列族 + 列名 + 版本号）定位到一个具体的值。</li>
</ul>
<table>
<thead>
<tr>
<th align="center">概念名称</th>
<th align="center">概念用途</th>
</tr>
</thead>
<tbody><tr>
<td align="center">行键（rowkey）</td>
<td align="center">用于唯一索引一行数据的“主键”以字典序组织，一行可以包含多个列族</td>
</tr>
<tr>
<td align="center">列族（column family）</td>
<td align="center">用于组织一系列列名，一个列族可以包含任意多个列名，每个列族的数据物理上相互独立的存储，以支持按列读取部分数据</td>
</tr>
<tr>
<td align="center">列名（column name）</td>
<td align="center">用于定位到一个具体的列，一个列明可以包含多个版本的数据。不需要预先定义列名，以支持半结构化的数据模型</td>
</tr>
<tr>
<td align="center">版本号（version）</td>
<td align="center">用于标识一个列内多个不同版本的数据，每个版本号对应一个值</td>
</tr>
<tr>
<td align="center">值（value）</td>
<td align="center">存储一个具体的值</td>
</tr>
</tbody></table>
<p>物理数据结构最小单元是 KeyValue 结构：</p>
<ul>
<li>每个版本的数据都携带全部行列信息</li>
<li>同一行，同一列族的数据物理上连续有序存储</li>
<li>同列族内的 KeyValue 按 rowkey 字典序升序，column qualifier 升序，version 降序排列。</li>
<li>不同列族的数据存储在相互独立的物理文件，列族间不保证数据全局有序</li>
<li>同列族下不同物理文件间保证数据全局有序</li>
<li>仅单个物理文件内有序</li>
</ul>
<p>适用场景</p>
<ul>
<li>“仅在线”的海量分布式 KV &#x2F; 宽表存储，数据量级可达到 PB 级以上</li>
<li>写密集型、高吞吐应用，可接受一定程度的时延抖动</li>
<li>字典序主键索引、批量顺序扫描多行数据的场景</li>
<li>Hadoop 大数据生态友好兼容</li>
<li>半结构化数据模型，行列稀疏的数据分析，动态增减列名</li>
<li>敏捷平滑的水平扩展能力快速响应数据体量、流量变化</li>
</ul>
<p>HBase 数据模型的优缺点</p>
<table>
<thead>
<tr>
<th align="center">优势</th>
<th align="center">缺点</th>
</tr>
</thead>
<tbody><tr>
<td align="center">稀疏表友好，不存储缺省列，支持动态新增列类型</td>
<td align="center">每条数据都要冗余存储行列信息</td>
</tr>
<tr>
<td align="center">支持保存多版本数据</td>
<td align="center">不支持二级索引，只能通过 rowkey 索引，查询效率依赖于 rowkey 设计</td>
</tr>
<tr>
<td align="center">支持只读取部分 column family 的数据，避免读取不必要的数据</td>
<td align="center">column family 数量较多时可能引发性能衰退</td>
</tr>
<tr>
<td align="center">支持的数据规模相比传统关系型数据库更高，更易水平扩展</td>
<td align="center">不支持数据类型，一律按字节数组存储</td>
</tr>
<tr>
<td align="center">支持 rowkey 字典序批量扫描数据</td>
<td align="center">仅支持单行内的原子性操作，无跨行事务保障</td>
</tr>
</tbody></table>
<h2 id="2-架构设计"><a href="#2-架构设计" class="headerlink" title="2. 架构设计"></a>2. 架构设计</h2><p>主要组件包括：</p>
<ul>
<li>HMaster：元数据管理，集群调度、保活</li>
<li>RegionServer：提供数据读写服务，每个实例负责若干互不重叠的 rowkey 区间内的数据。</li>
<li>ThriftServer：提供 Thrift API 读写代理层</li>
</ul>
<p>依赖组件包括：</p>
<ul>
<li>Zookeeper：分布式一致性共识协作管理，例如 HMaster 选主、任务分发、元数据变更管理等。</li>
<li>HDFS：分布式文件系统，HBase 数据存储底座。</li>
</ul>
<p>HMaster 主要职责：</p>
<ul>
<li>管理 RegionServer 实例生命周期，保证服务可用性</li>
<li>协调 RegionServer 数据保障恢复，保证数据正确性</li>
<li>集中管理集群元数据，执行负载均衡等维护集群稳定性</li>
<li>定期巡检元数据，调整数据分布，清理废弃数据等</li>
<li>处理用户主动发起的元数据操作如建表、删表等。</li>
</ul>
<p>HMaster 主要组件：</p>
<ul>
<li>ActiveMasterManager：管理 HMaster 的 active&#x2F;bankup 状态</li>
<li>ServerManager：管理集群内 RegionServer 的状态</li>
<li>AssignmentManager：管理数据分片（region）的状态</li>
<li>SplitWalManager：负责故障数据恢复的 WAL 拆分工作</li>
<li>LoadBalancer：定期巡检、调整集群负载状态</li>
<li>RegionNormalizer：定期巡检并拆分热点、整合碎片</li>
<li>CatalogJanitor：定期巡检、清理元数据</li>
<li>Cleaners：定期清理废弃的 HFile&#x2F;WAL 等文件</li>
<li>MasterFileSystem：封装访问 HDFS 的客户端 SDK</li>
</ul>
<p>RegionServer 主要职责</p>
<ul>
<li>提供部分 rowkey 区间数据的读写服务</li>
<li>如果负责 meta 表，向客户端 SDK 提供 workey 位置信息</li>
<li>认领 HMaster 发布的故障恢复任务，帮助加速数据恢复过程</li>
<li>处理 HMaster 下达的元数据操作，如 region 打开&#x2F;关闭&#x2F;分裂&#x2F;合并操作等</li>
</ul>
<p>RegionServer 主要组件</p>
<ul>
<li>MemStore：基于 SkipList 数据结构是西安的内存存储，定期批量写入硬盘</li>
<li>Write-Ahead-Log：顺序记录写请求到持久化存储，用于故障恢复内存中丢失的数据</li>
<li>StoreFile：即 HFile，表示  HBase 在 HDFS 存储数据的文件格式，其内数据按  rowkey 字典序有序排列</li>
<li>BlockCache：HBase 以数据块为单位读取数据并缓存在内存中以加速重复数据的读取</li>
</ul>
<p>Zookeeper 的主要职责</p>
<ul>
<li>HMaster 登记信息，对 active&#x2F;bankup 分工达成共识</li>
<li>RegionServer 登记信息，失联时 HMaster 保活处理</li>
<li>登记 meta 表位置信息，供 SDK 查询读写位置信息</li>
<li>供 HMaster 和 RegionServer 协作处理分布式任务</li>
</ul>
<p>ThriftServer 主要职责</p>
<ul>
<li>实现 HBase 定义的 Thrift API，作为代理层向用户提供 RPC 读写服务</li>
<li>用户可根据 IDL 自行生成客户端实现</li>
<li>独立于 RegionServer 水平扩展，用户可访问任意 ThriftServer 实例</li>
</ul>
<h2 id="3-大数据支撑"><a href="#3-大数据支撑" class="headerlink" title="3. 大数据支撑"></a>3. 大数据支撑</h2><p>HBase 在大数据生态的定位</p>
<ul>
<li>对 TB、PB 级海量数据支持强一致、近实时的读写性能，支持快速的 ad-hoc 分析查询任务；</li>
<li>支持字典序批量扫描大量数据，支持只读取部分列族的数据，灵活支持不同查询模式，避免读取不必要的数据；</li>
<li>存储大规模任务（例如 MapReduce，Spark，Flink）的中间&#x2F;最终计算结果；</li>
<li>平滑快速的水平扩展能力，能够敏捷应对大数据场景告诉增长的数据体量和大规模的并发访问；</li>
<li>精细化的资源成本控制，计算层和存储层分别按需扩展，避免资源浪费。</li>
</ul>
<p>水平扩展能力</p>
<ul>
<li>增加 RegionServer 实例，分配部分 region 到新实例。</li>
<li>扩展过程平滑，无需搬迁实际数据。</li>
<li>可用性影响时间很短，用户基本无感知。</li>
</ul>
<p>Region 热点切分</p>
<ul>
<li>当某个 region 数据量过时，切分成两个独立的子 region 分摊负载。</li>
<li>RegionServer 在特定时机（flush、compaction）检查 region 是否应该切分，计算切分点并 RPC 上报 HMaster，由 AssignmentManager 负责执行 RegionStateTransition。</li>
<li>不搬迁实际数据，切分产生的新 region 数据目录下生成一个以原 region 文件信息命名的文件，内容是切分点对象的 rowkey，以及标识新 region 是上&#x2F;下半部分的数据。</li>
</ul>
<p>Region 热点切分——切分点选取</p>
<p>HBase 原生提供的多种切分策略是用相同的切分点选择策略。</p>
<p>目标：优先把最大的数据文件均匀切分。</p>
<p>切分点选择的步骤：</p>
<ol>
<li>找到该表中哪个 region 的数据大小最大</li>
<li>找到该 region 内哪个 column family 的数据大小最大</li>
<li>找到 column family 内那哪个 HFile 的数据大小最大</li>
<li>找到 HFile 里处于最中间位置的 Data Block</li>
<li>用这个 Data Block 的第一条 Key&#x2F;Value 的 Rowkey 作为切分点</li>
</ol>
<p>Region 热点切分——切分过程</p>
<ul>
<li>所有 Column Family 都按照统一的切分点来切分数据</li>
<li>目的是优先均分最大的文件，不保证所有 Column Family 的所有文件都被均分</li>
<li>HFile 1 作为最大的文件被均分，其他文件也必须以相同的 rowkey 切分以保证对齐新的 region 的 rowkey 区间</li>
</ul>
<p>Region 热点切分——流程设计</p>
<p><img src="/blog/images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%20HBase%20%E5%AE%9E%E6%88%98/image-20220809180829694.png" alt="image-20220809180829694"></p>
<p>Region 碎片整合</p>
<ul>
<li>当某些 region 数据量过小、碎片化，合并相邻 region 整和优化数据分布</li>
<li>AssignmantManager 创建 MergeTableRegionsProcedure 执行整合操作</li>
<li>不搬迁实际数据，通过 reference file 定位原 region 的文件，直到下次 compaction 时实际处理数据</li>
</ul>
<blockquote>
<p>只允许合并相邻 region，否则会打破 rowkey 空间连续且不重合的约定</p>
</blockquote>
<p>Region 碎片整合——流程设计</p>
<p><img src="/blog/images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%20HBase%20%E5%AE%9E%E6%88%98/image-20220809181316506.png" alt="image-20220809181316506"></p>
<p>Region 负载均衡</p>
<p>定期巡检各 RegionServer 上的 region 数量，保持 region 的数量均匀分布在各个 RegionServer 上。</p>
<p>SimpleLoadBalancer 具体步骤：</p>
<ol>
<li><p>根据总 region 数量和 RegionServer 数量计算平均 region 数，设定弹性上下界避免不必要的操作。</p>
<blockquote>
<p>例如默认 slop 为 0.2，平均 region 数为 5，负载均衡的 RS 上 region 数量应该在 [4, 6] 区间内</p>
</blockquote>
</li>
<li><p>将 RegionServer 按照 region 数量降序排序，对 region 数量超出上限的选取要迁出的 region 并按创建时间从新到老排序</p>
</li>
<li><p>选取出 region 数量低于下限的 RegionServer 列表 round-robin 分配 2 选取的 regions，精良使用每个 RS 的 region 数量都不低于下限。</p>
</li>
<li><p>处理边界情况，无法满足所有 RS 的 region 数量都在合理范围内时，尽量保持 region 数量相近。</p>
</li>
</ol>
<p>其他策略：</p>
<ul>
<li>StochasticLoadBalancer<ul>
<li>随机尝试不同的 region 放置策略，根据提供的 cost function 计算不同策略的分值排名（0 为最优策略，1 为最差策略）；</li>
<li>cost 计算将将下列指标纳入统计：region 负载、表负载、数据本地性（本地访问 HDFS）、Memstore 大小、HFile 大小；</li>
<li>根据配置甲醛计算最终 cost，选择最优方案进行负载均衡。</li>
</ul>
</li>
<li>FavoredNodeLoadBalancer<ul>
<li>用于充分利用本地读写 HDFS 文件来优化读写性能；</li>
<li>每个 region 会指定优选的 3 个 RegionServer 地址，同时会告知 HDFS 在这些优选节点上放置该 region 的数据；</li>
<li>即使第一节点出现故障，HBase 也可以将第二节点提升为第一节点，保证稳定的读时延。</li>
</ul>
</li>
</ul>
<p>故障恢复机制——HMaster</p>
<p>HMaster 通过多实例基于 Zookeeper 选主实现高可用性。</p>
<ul>
<li>所有实力尝试向 Zookeeper 的 &#x2F;hbase&#x2F;active-master 临时节点 CAS 地写入自身信息</li>
<li>写入成功表示成为主实例，失败即为从实例，通过 watch 监听 &#x2F;hbase&#x2F;active-master 节点地变动。</li>
<li>主实例不可用时临时节点被删除，此时触发其他从实例重新尝试选主。</li>
</ul>
<p>恢复流程</p>
<ul>
<li>HMaster 自身恢复流程<ol>
<li>监听到 &#x2F;hbase&#x2F;active-master 临时节点被删除的事件，触发选主逻辑。</li>
<li>选主成功后执行 HMaster 启动流程，从持久化存储读取未完成的 procedures 从之前状态继续执行。</li>
<li>故障 HMaster 实例恢复后发现主节点已存在，继续监听 &#x2F;hbase&#x2F;active-master</li>
</ol>
</li>
<li>调度 RegionServer 的故障恢复流程<ol>
<li>AssignmentManager 从 procedure 列表中找出 Region-In-Transition 状态的 region 继续调度过程。</li>
<li>RegionServerTracker 从 Zookeeper 梳理 online 状态的 RegionServer 列表，结合 ServerCrashProcedure 列表、HDFS 中 WAL 目录里 alive&#x2F;spliting 状态的 RegionServer 记录，获取掉线 RegionServer 的列表，分别创建 ServerCrashProcedure 执行恢复流程。</li>
</ol>
</li>
</ul>
<p>故障恢复机制——RegionServer</p>
<ul>
<li>每个 RegionServer 实例启动时都会往 Zookeeper 的 &#x2F;hbase&#x2F;rs 路径下创建对象的临时节点</li>
<li>HMaster 通过监听 RegionServer 在 Zookeeper 的临时节点状态，监控数据读写服务的可用性，及时调度恢复不可用的 regions。</li>
<li>RegionServer 的故障恢复需要将内存中丢失的数据从 WAL 中恢复，HMaster 利用 Zookeeper 配合所有 RegionServer 实例，分布式地处理 WAL 数据，提升恢复速度。</li>
</ul>
<p>恢复流程：</p>
<ol>
<li>启动时去 Zookeeper 登记自身信息，告知主 HMaster 实例有新 RS 实例接入集群</li>
<li>接收和执行来自 HMaster 的 region 调度指令</li>
<li>打开 region 前先从 HDFS 读取该 region 的 recovered.edits 目录下的 WAL 记录，回放恢复数据</li>
<li>恢复完成，认领 Zookeeper 上发布的分布式任务（如 WAL 切分）帮助其他数据恢复</li>
</ol>
<p>Distributed Log Split 原理</p>
<p>背景：</p>
<ol>
<li>写入 HBase 的数据首先顺序持久化到 Write-Ahead-Log，然后写入内存态的 MemStore 即完成，不立即写盘，RegionServer 故障会导致内存中的数据丢失，需要回放 WAL 来恢复；</li>
<li>同 RegionServer 的所有 region 复用 WAL，因此不同 region 的数据交错穿插，RegionServer 故障后重新分配 region 前需要先按 region 维度拆分 WAL</li>
</ol>
<p>具体流程</p>
<ol>
<li>RegionServer 故障，Zookeeper 检测到心跳超时或连接断开，删除对应的临时节点并通知监听该节点的客户端</li>
<li>active HMaster 监听到 RS 临时节点删除事件，从 HDFS 梳理出该 RS 负责的 WAL 文件</li>
<li>HMaster 为每个 WAL 文件发布一个 log split task 到 ZK</li>
<li>其他在线的 RS 监听到新任务，分别认领</li>
<li>将 WAL entries 按 region 拆分，分别写入 HDFS 上该 region 的 recovered.edits 目录</li>
<li>HMaster 监听到 log split 任务完成，调度 region 到其他 RS</li>
<li>RS 打开 region 前在 HDFS 找到先回放 recoverd.edits 目录下的 WAL 文件将数据恢复到 Memstore 里，再打开 region 恢复读写服务</li>
</ol>
<p>进一步优化：</p>
<ul>
<li>HMaster 先将故障 RegionServer 上的所有 region 以 Recovering 状态调度分配到其他正常 RS 上</li>
<li>在进行类似 Distributed Log Split 的 WAL 日志按 region 维度切分</li>
<li>切分后不写入 HDFS，而是直接回放，通过 SDK 写流程将 WAL 记录写到对象的新 RS</li>
<li>Recovering 状态的 region 接受写请求但不提供读服务，知道 WAL 回放数据恢复完成。</li>
</ul>
<h2 id="4-最佳实践"><a href="#4-最佳实践" class="headerlink" title="4. 最佳实践"></a>4. 最佳实践</h2><p><img src="/blog/images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%20HBase%20%E5%AE%9E%E6%88%98/image-20220809190038678.png" alt="image-20220809190038678"></p>
<p><img src="/blog/images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%20HBase%20%E5%AE%9E%E6%88%98/image-20220809190056642.png" alt="image-20220809190056642"></p>
<p><img src="/blog/images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%20HBase%20%E5%AE%9E%E6%88%98/image-20220809190152135.png" alt="image-20220809190152135"></p>
<p>参数调优</p>
<p><img src="/blog/images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%20HBase%20%E5%AE%9E%E6%88%98/image-20220809190253753.png" alt="image-20220809190253753"></p>
<p>ByteTable</p>
<p><img src="/blog/images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%20HBase%20%E5%AE%9E%E6%88%98/image-20220809190420017.png" alt="image-20220809190420017"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://the_ring.gitee.io/blog/2022/08/09/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%20HBase%20%E5%AE%9E%E6%88%98/" data-id="cl79sj7gx000xzgute2b44yh1" data-title="深入浅出 HBase 实战" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/HBase/" rel="tag">HBase</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/bid-data/" rel="tag">bid data</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-HDFS 高可用和高扩展机制分析" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/blog/2022/08/05/HDFS%20%E9%AB%98%E5%8F%AF%E7%94%A8%E5%92%8C%E9%AB%98%E6%89%A9%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/" class="article-date">
  <time class="dt-published" datetime="2022-08-05T05:08:36.000Z" itemprop="datePublished">2022-08-05</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/blog/2022/08/05/HDFS%20%E9%AB%98%E5%8F%AF%E7%94%A8%E5%92%8C%E9%AB%98%E6%89%A9%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/">HDFS 高可用和高扩展机制分析</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-元数据高可用"><a href="#1-元数据高可用" class="headerlink" title="1. 元数据高可用"></a>1. 元数据高可用</h2><p>高可用的衡量</p>
<p><img src="/blog/../images/HDFS%20%E9%AB%98%E5%8F%AF%E7%94%A8%E5%92%8C%E9%AB%98%E6%89%A9%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/image-20220805131626421.png" alt="image-20220805131626421"></p>
<p>可用性年化</p>
<p><img src="/blog/../images/HDFS%20%E9%AB%98%E5%8F%AF%E7%94%A8%E5%92%8C%E9%AB%98%E6%89%A9%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/image-20220805131730291.png" alt="image-20220805131730291"></p>
<p>高可用的形式</p>
<p>HDFS 设计中，采用了中心化的元数据管理节点 NameNode。NameNode 容易称为故障中的单点（sngle point of failure）。</p>
<p>HDFS NameNode 高可用架构</p>
<ul>
<li>组件介绍<ul>
<li>ActiveNamenode：主节点，提供服务，生产日志</li>
<li>StandbyNamenode：备节点，消费日志</li>
<li>Zookeeper：为自动选主剔红统一协调服务</li>
<li>BookKeeper：提供日志存储服务</li>
<li>ZKFC：NameNode 探活、触发主备切换</li>
<li>HA Client：提供了自动切换的客户端</li>
<li>edit log：操作日志</li>
</ul>
</li>
<li>围绕三个问题来看高可用<ul>
<li>节点状态如何更新</li>
<li>操作日志如何同步</li>
<li>如何做到自动切换</li>
</ul>
</li>
</ul>
<p><img src="/blog/../images/HDFS%20%E9%AB%98%E5%8F%AF%E7%94%A8%E5%92%8C%E9%AB%98%E6%89%A9%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/image-20220805132032154.png" alt="image-20220805132032154"></p>
<p>理论基础——状态机复制和日志</p>
<p>状态机复制是实现容错的常规方法，组件：状态机及其副本、变更日志、共识协议。</p>
<p>NameNode 操作日志的生产消费</p>
<p>NameNode 块状态维护</p>
<p>分布式协调组件——Zookeeper</p>
<p>自动主备切换流程</p>
<p>Server侧</p>
<ol>
<li>ZKFailvorController：作为外部组件，驱动 HDFS NameNode 的主备切换</li>
<li>轮询探活</li>
<li>脑裂问题</li>
<li>Fence 机制</li>
</ol>
<p>Client侧</p>
<p>核心机制：StandbyException</p>
<p>Client 自动处理</p>
<p>BookKeeper 架构</p>
<p>BookKeeper 存储日志</p>
<ul>
<li>低延迟</li>
<li>持久性</li>
<li>强一致性</li>
<li>读写高可用</li>
</ul>
<p>对比：日志系统和文件系统的复杂度</p>
<p>Quorum 机制</p>
<p>Quorum 机制：多副本一致性读写</p>
<p>场景：多副本对象存储，用版本号标识数据新旧</p>
<p>BookKeeper Quorum</p>
<p>Sloppy Quorum 机制</p>
<p>日志场景：顺序追加、只写</p>
<p>Write Quorum：写入副本数</p>
<p>Ack Quorum：响应副本数</p>
<p>BookKeeper Ensemble</p>
<p>Ensemble 机制</p>
<h2 id="2-数据存储高可用"><a href="#2-数据存储高可用" class="headerlink" title="2. 数据存储高可用"></a>2. 数据存储高可用</h2><p>回到单机存储——RAID</p>
<p>Redundant Array of Independent Disks</p>
<p>特点</p>
<ul>
<li>廉价</li>
<li>高性能</li>
<li>大容量</li>
<li>高可用</li>
</ul>
<p>RAID 方案讲解</p>
<p>RAID 0：条带化</p>
<p>RAID 1：冗余</p>
<p>RAID 3：容错校验</p>
<p>HDFS 多副本</p>
<p>HDFS 版本的 RAID 1</p>
<p>优点：</p>
<ul>
<li>读写路径简单</li>
<li>副本修复简单</li>
<li>高可用</li>
</ul>
<p>Erasure Coding 原理</p>
<p>HDFS 版本的 RAID 2&#x2F;3</p>
<p>业界常用 Reed Solomon 算法</p>
<p>HDFS Erasure Coding</p>
<p>HDFS 版本的 RAID 2</p>
<p>和多副本比较</p>
<ul>
<li>读写速度</li>
<li>成本</li>
<li>修复速度</li>
<li>读写路径的实现</li>
</ul>
<p>初始网络架构</p>
<p>Server：一台服务器</p>
<p>机架（Rack）：放服务器的架子</p>
<p>TOR（Top of Rack）机架顶部的交换机</p>
<p>POD（Point of Delivery）数据中心中的一个物理区域</p>
<p>数据中心（Data Center）：集中部署服务器的场所</p>
<p>副本放置策略——机架感知</p>
<p>一个 TOR 故障导致整个机架不可用</p>
<p>降低跨 rack 流量</p>
<p>trade-off：一个本地、一个远端</p>
<p>案例：HDFS 多机房实践</p>
<p>多机房解决问题</p>
<ul>
<li>容量问题</li>
<li>容灾问题</li>
</ul>
<p>HDFS 双机房放置设计</p>
<ul>
<li>写入时，每个数据块在两个机房至少各有一个副本，数据实时吸入到两个机房</li>
<li>读取时，有限读本地的副本，避免了大量的跨机房读取</li>
</ul>
<p>多机房容灾实践</p>
<p>多机房部署的组件</p>
<ul>
<li>Zookeeper</li>
<li>BookKeeper</li>
<li>NameNode</li>
<li>DataNode</li>
</ul>
<p>容灾期间的策略</p>
<ul>
<li>容灾期间，限制跨机房写入</li>
<li>容灾期间，限制跨机房副本复制</li>
</ul>
<h2 id="3-元数据高扩展性"><a href="#3-元数据高扩展性" class="headerlink" title="3. 元数据高扩展性"></a>3. 元数据高扩展性</h2><p>元数据节点扩展性的挑战</p>
<p>HDFS NameNode 是个集中式服务，部署在单个机器上，内存和磁盘的容量、CPUU 的计算力都不能无限扩展</p>
<p>scale up vs. scale out</p>
<ul>
<li>扩容单个服务器的能力</li>
<li>部署多个服务器来服务</li>
</ul>
<p>挑战</p>
<ul>
<li>米子空间分裂</li>
<li>DataNode 汇报</li>
<li>目录树结构本身复杂</li>
</ul>
<p>常见的 Scale Out 方案</p>
<p>KV 模型的系统可以使用 partition</p>
<ul>
<li>Redis</li>
<li>Kafka</li>
<li>MySQL（分库分表）</li>
</ul>
<p>三种数据路由方式：</p>
<ul>
<li>服务端侧</li>
<li>路由层</li>
<li>客户端侧</li>
</ul>
<p>社区解决方案——BlockPool</p>
<p>解决 DN 同时服务多组 NN 的问题</p>
<ul>
<li>同一个 block id 在不同的 NN 上出现</li>
</ul>
<p>文件服务分层</p>
<ul>
<li>Namespace</li>
<li>Block Storage</li>
</ul>
<p>用 blockpool 来区分 DN 的服务</p>
<ul>
<li>数据块存储</li>
<li>心跳和块上报</li>
</ul>
<p>社区解决方案——viewfs</p>
<p>Federation 结构：将多个不同集群组合起来，对外表现向一个集群一样</p>
<p>viewfs 通过在 client-side 的配置，指定不同的目录访问不同的 NameNode</p>
<p>局限性：运维复杂</p>
<p>字节跳动的 NNProxy</p>
<p>NNProxy 是字节字眼的 HDFS 代理层，提供了路由服务</p>
<p>NNProxy 主要实现了路由管理和 RPC 转发以及鉴权、限流、查询缓存等额外功能</p>
<p>NNProxy 路由规则保存</p>
<p>三种数据路由方式：</p>
<ul>
<li>服务端侧</li>
<li>路由层</li>
<li>客户端侧</li>
</ul>
<p>考虑点：扩展性、运维性</p>
<p>NNProxy 路由转发实现</p>
<p>路径最长匹配规则，可以进一步划分目录树</p>
<p>进一步思考：</p>
<ul>
<li>单个 NN 不会遇到瓶颈吗？</li>
<li>跨集群 rename</li>
</ul>
<p>案例：小文件问题</p>
<p>小文件问题（LSOF，lots of small files）：大小不到一个 HDFS Block 大小的文件过多</p>
<ul>
<li>NameNode 瓶颈</li>
<li>I&#x2F;O 变成小的随机 IO，数据访问变慢</li>
<li>计算任务启动慢</li>
</ul>
<p>解决方案：</p>
<ul>
<li>后台任务合并小文件</li>
<li>Shuffle Service</li>
</ul>
<h2 id="4-数据存储高扩展性"><a href="#4-数据存储高扩展性" class="headerlink" title="4. 数据存储高扩展性"></a>4. 数据存储高扩展性</h2><p>延迟的分布和长尾延迟</p>
<p>延迟的分布：</p>
<ul>
<li>用百分数来表示发个文的延迟的统计特征</li>
<li>例如 p95 延迟 1,s，代表 95% 的请求延迟要低于 1ms，但后 5% 的请求延迟会大于 1ms</li>
</ul>
<p>长尾延迟：尾部（p99&#x2F;p999&#x2F;p9999）的延迟，衡量系统最差的请求情况，会显著的要差于平均值</p>
<p>尾部延迟放大</p>
<p>木桶原理：尾部延迟放大：访问的服务变多，尾部的请求就会越发的慢</p>
<p>如何变慢</p>
<ul>
<li>固定延迟阈值</li>
<li>固定延迟百分位</li>
</ul>
<p>长尾问题的表现——慢节点</p>
<p>慢节点：读取速度过慢，导致客户端阻塞</p>
<p>慢节点的发生难以避免和预测</p>
<ul>
<li>共享资源、后台维护活动、请求多级排队、功率限制</li>
<li>固定的损耗：机器损坏率</li>
<li>混沌问题</li>
</ul>
<p>离线任务也会遇到长尾问题</p>
<ul>
<li>全部任务完成时间取决于最慢的任务什么时候完成</li>
<li>集群规模变大，任务的数据量变大</li>
<li>只要任何数据块的读取受到长尾影响，整个任务就会因此停滞</li>
</ul>
<p>集群扩大 10 倍，问题扩大 N（&gt;10）倍</p>
<p>超大集群下的数据可靠性</p>
<ul>
<li>条件一：超大集群下，有一部分机器损坏来不及修理的。</li>
<li>条件二：副本放置策略完全随机</li>
<li>条件三：DN 容量足够大</li>
</ul>
<p>推论：必然有部分数据全部副本在损坏的机器上，发生数据丢失</p>
<p>估算：三副本，10000 台机器，每台一百万副本。</p>
<ul>
<li>有多少种放置组合数</li>
<li>损坏 100 台机器，会有多少副本丢失</li>
</ul>
<p>叠加长尾问题，容易导致整个任务无法执行下去</p>
<p>Copyset</p>
<p>将 DataNode 分为若干个 Copyset 选块在 Copyset 内部选择</p>
<p>原理：减少了副本放置的组合数，从而降低副本丢失的概率</p>
<p>超大集群的负载均衡和数据迁移</p>
<p><img src="/blog/../images/HDFS%20%E9%AB%98%E5%8F%AF%E7%94%A8%E5%92%8C%E9%AB%98%E6%89%A9%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/image-20220805143659568.png" alt="image-20220805143659568"></p>
<p>数据写入&#x2F;读取不均</p>
<p>数据的不均匀</p>
<ul>
<li>节点容量不均匀</li>
<li>数据新旧不均匀</li>
<li>访问类型不均匀</li>
</ul>
<p>资源负载不均匀</p>
<p>负载均衡和数据迁移的典型场景</p>
<p><img src="/blog/../images/HDFS%20%E9%AB%98%E5%8F%AF%E7%94%A8%E5%92%8C%E9%AB%98%E6%89%A9%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/image-20220805143930787.png" alt="image-20220805143930787"></p>
<p>数据迁移工具——跨 NN 迁移</p>
<p>DistCopy</p>
<ul>
<li>基于 MapReduce，通过一个个任务，将数据从一个 NameNode 拷贝到另一个 NameNode</li>
<li>需要拷贝数据，流量较大，速度较慢</li>
</ul>
<p>FastCopy</p>
<ul>
<li>开源社区的无需拷贝数据的源数据迁移方案</li>
<li>前提条件：新旧集群的 DN 列表吻合</li>
<li>对于元数据，直接复制目录树的结构和块信息</li>
<li>对于数据块，直接要求 DataNode 从源 BlockPool hardlink 到目标 BlookPool，没有数据拷贝</li>
<li>hardlink：直接让两个路径指向同一个块数据</li>
</ul>
<p>数据迁移工具——Balancer</p>
<p>工具向 DataNode 发起迁移指令，平衡各个 DataNode 的容量</p>
<p>场景：</p>
<ul>
<li>单机房使用、多机房使用</li>
<li>限流措施</li>
</ul>
<p>评价标准</p>
<ul>
<li>稳定性成本</li>
<li>可运维性</li>
<li>执行效率</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://the_ring.gitee.io/blog/2022/08/05/HDFS%20%E9%AB%98%E5%8F%AF%E7%94%A8%E5%92%8C%E9%AB%98%E6%89%A9%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/" data-id="cl79sj7gm0003zgutddmga3nz" data-title="HDFS 高可用和高扩展机制分析" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/HDFS/" rel="tag">HDFS</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/big-data/" rel="tag">big data</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-HDFS 原理与应用" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/blog/2022/08/05/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/" class="article-date">
  <time class="dt-published" datetime="2022-08-05T04:05:10.000Z" itemprop="datePublished">2022-08-05</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/blog/2022/08/05/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/">HDFS 原理与应用</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-HDFS-基本介绍"><a href="#1-HDFS-基本介绍" class="headerlink" title="1. HDFS 基本介绍"></a>1. HDFS 基本介绍</h2><p>Windows 文件系统：NTFS</p>
<p>Linux 文件系统：BTRFS、ZFS、XFS、EXT4</p>
<p>分布式文件系统：大容量（更多的机器，更多的存储介质）、高可靠（多个副本提高容错能力）、低成本（不需要高端硬件来扩容）</p>
<p><img src="/blog/images/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/image-20220805121036274.png" alt="image-20220805121036274"></p>
<h4 id="HDFS-功能特性："><a href="#HDFS-功能特性：" class="headerlink" title="HDFS 功能特性："></a>HDFS 功能特性：</h4><ol>
<li>分布式：受 GFS 启发，用 Java 实现的开源系统，没有实现完整的 POSIX 文件系统的语义</li>
<li>容错：自动处理，规避多种错误场景，例如常见的网络错误、机器宕机等</li>
<li>高可用：一主多备模式实现袁术高可用，数据多副本实现用户数据的高可用</li>
<li>高吞吐：Client 直接从 DataNode 读取用户数据，服务端支持海量 Client 读写</li>
<li>可扩展：支持联邦集群模式，DataNode 数量高达 10W 级别</li>
<li>廉价：只需要通用硬件，不需要定制高端的昂贵硬件设备</li>
</ol>
<h2 id="2-架构原理"><a href="#2-架构原理" class="headerlink" title="2. 架构原理"></a>2. 架构原理</h2><h4 id="Client-写流程："><a href="#Client-写流程：" class="headerlink" title="Client 写流程："></a>Client 写流程：</h4><p><img src="/blog/images/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/image-20220805121752901.png" alt="image-20220805121752901"></p>
<h4 id="Client-读流程："><a href="#Client-读流程：" class="headerlink" title="Client 读流程："></a>Client 读流程：</h4><p><img src="/blog/images/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/image-20220805121944362.png" alt="image-20220805121944362"></p>
<h4 id="元数据节点-NameNode："><a href="#元数据节点-NameNode：" class="headerlink" title="元数据节点 NameNode："></a>元数据节点 NameNode：</h4><ul>
<li><strong>维护目录树</strong>：维护目录树的增删改查，保证所有数据修改都能持久化，以便机器掉电不会造成数据丢失或不一致。</li>
<li><strong>维护文件和数据块的关系</strong>：文件被切分成多个快，文件以数据快为单位进行多副本存放。</li>
<li><strong>维护文件快存放节点信息</strong>：通过接收 DataNode 的心跳汇报信息，维护集群节点的拓扑结构和每个文件块所有副本所在的 DataNode 类表。</li>
<li><strong>分配新文件存放节点</strong>：Client 创建新的文件时，需要 NameNode 来确定目标 DataNode。</li>
</ul>
<h4 id="数据节点-DataNode："><a href="#数据节点-DataNode：" class="headerlink" title="数据节点 DataNode："></a>数据节点 DataNode：</h4><ul>
<li><strong>数据块存取</strong>：DataNode 需要高效实现对数据块在硬盘上的存取。</li>
<li><strong>心跳汇报</strong>：把存放在本机的数据块发送给 NameNode，以便 NameNode 能维护数据块的位置信息，同时让 NameNode 确定该节点处于正常存活状态。</li>
<li><strong>副本复制</strong>：数据写入时 Pipeline IO 操作；机器故障时补全副本。</li>
</ul>
<h2 id="3-关键设计"><a href="#3-关键设计" class="headerlink" title="3. 关键设计"></a>3. 关键设计</h2><h4 id="分布式存储系统基本概念："><a href="#分布式存储系统基本概念：" class="headerlink" title="分布式存储系统基本概念："></a>分布式存储系统基本概念：</h4><ol>
<li><strong>容错能力</strong>：能够让绝大部分异常场景，例如服务器当即、网络异常、硬盘故障、网络超时等。</li>
<li><strong>一致性模型</strong>：为了实现容错，数据必须多副本存放，一致性要解决的问题是如何保障多个副本的内容都是一致的。</li>
<li><strong>可扩展性</strong>：分布式存储系统需要具备横向扩张 scale-out 的能力。</li>
<li><strong>节点体系</strong>：常见的有主从模式、对等模式，不管哪种模式，高可用是必须的功能。</li>
<li><strong>数据放置</strong>：系统是由多个节点组成，数据是多个副本存放时，需要考虑存放的策略。</li>
<li><strong>单机存储引擎</strong>：在绝大多数存储系统中，数据都是需要落盘持久化，单机引擎需要解决的是根据系统特点，如何高效地存取硬盘数据。</li>
</ol>
<h4 id="NameNode-目录是维护"><a href="#NameNode-目录是维护" class="headerlink" title="NameNode 目录是维护"></a>NameNode 目录是维护</h4><ul>
<li>fsimage<ul>
<li>文件系统目录树</li>
<li>完整的存放在内存</li>
<li>定时存放到硬盘上</li>
<li>修改时指挥修改内存中的目录树</li>
</ul>
</li>
<li>EditLog<ul>
<li>目录树的修改日志</li>
<li>client 更新目录树需要持久化 EditLog 后才能表示更新成功</li>
<li>EditLog 可存放在本地文件系统，也可存放在专用系统上</li>
<li>NameNode HA 方案一贯关键点就是如何实现 EditLog 共享</li>
</ul>
</li>
</ul>
<h4 id="NameNode-数据放置"><a href="#NameNode-数据放置" class="headerlink" title="NameNode 数据放置"></a>NameNode 数据放置</h4><ul>
<li>数据快信息维护<ul>
<li>目录树保存了每个文件的块 id</li>
<li>NameNode 维护了每个数据块所在的节点信息</li>
<li>NameNode 根据 DataNode 汇报的信息动态维护位置信息</li>
<li>NameNode 不会持久化数据块位置信息</li>
</ul>
</li>
<li>数据块放置策略<ul>
<li>新数据存放到哪个写节点</li>
<li>数据均衡需要怎么合理搬迁数据</li>
<li>3 个副本怎么合理放置</li>
</ul>
</li>
</ul>
<h4 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h4><ul>
<li>数据块的硬盘存放<ul>
<li>文件在 NameNode 已分割成 block</li>
<li>DateNode 以 block 为单位对数据进行存取</li>
</ul>
</li>
<li>启动扫盘<ul>
<li>DataNode 需要知道本机存放了哪些数据块</li>
<li>启动时把本机硬盘上的数据块列表加载在内存中</li>
</ul>
</li>
</ul>
<h4 id="HDFS-写异常处理"><a href="#HDFS-写异常处理" class="headerlink" title="HDFS 写异常处理"></a>HDFS 写异常处理</h4><p><strong>情景</strong>：文件写了一半，client 自己挂掉了。可能产生的问题：</p>
<ul>
<li>副本不一致</li>
<li>Lease 无法释放</li>
</ul>
<p><strong>租约</strong>：Client 要修改一个文件，需要通过 NameNode 上锁，这个所就是租约（Lease）</p>
<p><strong>解决办法</strong>：Lease Recovery</p>
<p><strong>情景</strong>：文件写入过程中，DataNode 侧出现异常挂掉了。</p>
<p><strong>异常出现的时机</strong>：</p>
<ul>
<li>创建连接时</li>
<li>数据传输时</li>
<li>complete 阶段</li>
</ul>
<p><strong>解决办法</strong>：Pipeline Recovery</p>
<h4 id="HDFS-读异常处理"><a href="#HDFS-读异常处理" class="headerlink" title="HDFS 读异常处理"></a>HDFS 读异常处理</h4><p><strong>情景</strong>：读取文件的过程，DataNode 侧出现异常挂掉了</p>
<p><strong>解决办法</strong>：节点 Failover</p>
<p><strong>增强情景</strong>：节点半死不过，读取很慢</p>
<h4 id="旁路系统"><a href="#旁路系统" class="headerlink" title="旁路系统"></a>旁路系统</h4><p><strong>Balancer</strong>：均衡 DataNode 的容量</p>
<p><strong>Mover</strong>：确保副本放置符合策略要求</p>
<h4 id="控制面建设"><a href="#控制面建设" class="headerlink" title="控制面建设"></a>控制面建设</h4><p><strong>可观测性设施</strong>：</p>
<ul>
<li>指标埋点</li>
<li>数据采集</li>
<li>访问日志</li>
<li>数据分析</li>
</ul>
<p><strong>运维体系建设</strong></p>
<ul>
<li>运维操作需要平台化</li>
<li>NameNode 操作复杂</li>
<li>DataNode 机器规模庞大</li>
<li>组件控制面 API</li>
</ul>
<h2 id="4-应用场景"><a href="#4-应用场景" class="headerlink" title="4. 应用场景"></a>4. 应用场景</h2><h4 id="ETL"><a href="#ETL" class="headerlink" title="ETL"></a>ETL</h4><p><img src="/blog/images/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/image-20220805130350452.png" alt="image-20220805130350452"></p>
<h4 id="OLAP-查询引擎"><a href="#OLAP-查询引擎" class="headerlink" title="OLAP 查询引擎"></a>OLAP 查询引擎</h4><p><img src="/blog/images/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/image-20220805130455511.png" alt="image-20220805130455511"></p>
<h4 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h4><p><img src="/blog/images/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/image-20220805130530917.png" alt="image-20220805130530917"></p>
<h4 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h4><p><img src="/blog/images/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/image-20220805130609707.png" alt="image-20220805130609707"></p>
<h4 id="通用存储应用"><a href="#通用存储应用" class="headerlink" title="通用存储应用"></a>通用存储应用</h4><p><img src="/blog/images/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/image-20220805130649802.png" alt="image-20220805130649802"></p>
<blockquote>
<p>MIT 8.624</p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://the_ring.gitee.io/blog/2022/08/05/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/" data-id="cl79sj7gj0001zgut06ffgzz7" data-title="HDFS 原理与应用" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/HDFS/" rel="tag">HDFS</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/big-data/" rel="tag">big data</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-Presto 架构原理与优化介绍" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/blog/2022/08/03/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/" class="article-date">
  <time class="dt-published" datetime="2022-08-03T02:10:10.000Z" itemprop="datePublished">2022-08-03</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/blog/2022/08/03/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/">Presto 架构原理与优化</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><h3 id="1-1-大数据与-OLAP-的演进"><a href="#1-1-大数据与-OLAP-的演进" class="headerlink" title="1.1. 大数据与 OLAP 的演进"></a>1.1. 大数据与 OLAP 的演进</h3><p>OLAP（OnLine Analytical Processing）对业务数据执行多维分析，并提供复杂计算，趋势分析和复杂数据建模的能力。是许多商务智能（BI）应用程序背后的技术。</p>
<p>OLAP 核心概念：维度、度量</p>
<p>常见的  OLAP 引擎：</p>
<ul>
<li>与计算引擎：Kylin、Druid</li>
<li>批式处理引擎：Hive、Saprk</li>
<li>流式处理引擎：Flink</li>
<li>交互式处理引擎：Presto、Clickhosue、Doris</li>
</ul>
<h3 id="1-2-Presto-设计思想"><a href="#1-2-Presto-设计思想" class="headerlink" title="1.2. Presto 设计思想"></a>1.2. Presto 设计思想</h3><p>Presto 最初由 Facebook 研发的构建于 Hadoop&#x2F;HDFS 系统之上的 PB 集交互式分析引擎，具有以下特点：</p>
<ul>
<li>多租户任务的管理与调度</li>
<li>多数据源联邦查询</li>
<li>支持内存优化计算</li>
<li>Pipline 式数据处理</li>
</ul>
<h2 id="2-Presto-基础原理和概念"><a href="#2-Presto-基础原理和概念" class="headerlink" title="2. Presto 基础原理和概念"></a>2. Presto 基础原理和概念</h2><h3 id="2-1-基础原理与概念"><a href="#2-1-基础原理与概念" class="headerlink" title="2.1. 基础原理与概念"></a>2.1. 基础原理与概念</h3><p><strong>服务相关</strong></p>
<p><img src="/blog/images/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/image-20220803102720230.png" alt="image-20220803102720230"></p>
<ul>
<li>Coordinator<ul>
<li>解析 SQL 语句</li>
<li>生成执行计划</li>
<li>分发执行任务给 Worker 节点</li>
</ul>
</li>
<li>Worker<ul>
<li>执行 Task 处理数据</li>
<li>与其他 Worker 交互传输数据</li>
</ul>
</li>
</ul>
<p><strong>数据源相关</strong></p>
<p><img src="/blog/images/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/image-20220803103002056.png" alt="image-20220803103002056"></p>
<ul>
<li>Connector：一个 Connector 代表一种数据源，可以认为 Connector 是由 Presto 提供的适配多数据源的统一接口。</li>
<li>Catalog：管理员辕信息与实际数据的映射关系。</li>
</ul>
<p><strong>Query 相关</strong></p>
<ul>
<li>Query：基于 SQL parser 后获得的执行计划。</li>
<li>Stage：根据是否需要 shuffle 将 Query 拆分成不同的 subplan，欸一个 subplan 是一个 stage。</li>
<li>Fragment：基本等价于 stage，属于不同阶段的称呼。</li>
<li>Task：单个 Worker 节点上的最小资源管理单元，在一个节点上，一个 Stage 只有一个 Task，一个 Query 可能有多个 Task。</li>
<li>Pipeline：Stage 按照 LocalExchange 切分为若干 Operator 集合，每个 Operator 集合定义一个 Pipeline。</li>
<li>Driver：Pipeline 的可执行实体，Pipeline 和 Driver 的关系可类比为程序和进程，是最小的执行单元，通过火山迭代模型执行每一个 Operator。</li>
<li>Split：输入数据描述（数据实体是 Page)，数量上和 Driver 一一对应，不仅代表实际数据源 split，也代表了不同 stage 间传输的数据。</li>
<li>Operator：最小物理算子。</li>
</ul>
<p><strong>数据传输相关</strong></p>
<ul>
<li>Exchange：表示不同 Stage 间的数据传输，大多数意义下等价于 Shuffle。</li>
<li>LocalExchange：Stage 内的 rehash 操作，常用于提高并行处理数据的能力（Task 在 Presto 中只是最小的容器，而不是最小的执行单元），<u>默认值是16</u>。</li>
</ul>
<h3 id="2-2-核心组件结构介绍"><a href="#2-2-核心组件结构介绍" class="headerlink" title="2.2. 核心组件结构介绍"></a>2.2. 核心组件结构介绍</h3><p><strong>Presto 结构图</strong></p>
<p><img src="/blog/images/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/image-20220803104359902.png" alt="image-20220803104359902"></p>
<p><strong>服务发现</strong></p>
<p>Discovery Service：</p>
<ol>
<li>Worker 配置文件配置 Discovery Service 地址</li>
<li>Worker 节点启动后会向 Discovery Service 注册</li>
<li>Coordinator 从 Discovery Service 获取 Worker 的地址</li>
</ol>
<p><strong>通信机制</strong></p>
<ul>
<li><p>通信机制</p>
<ol>
<li>Presto Client &#x2F; JDBC Client 与 Server 间通信 —- htpp</li>
<li>Coordinator 与 Worker 间的通信 —- Thrift&#x2F;Http</li>
<li>Worker 与 Worker 间的通信 —- Thrift&#x2F;Http</li>
</ol>
<blockquote>
<p>Thrift 具有更好的数据编码能力，Http 1.1 还不支持头部信息的压缩，Thrift 具有更好的数据压缩能力</p>
</blockquote>
</li>
<li><p>节点状态</p>
<ul>
<li>ACTIVE</li>
<li>INACTIVE</li>
<li>SHUTDOWN</li>
</ul>
</li>
</ul>
<h2 id="3-Presto-重要机制"><a href="#3-Presto-重要机制" class="headerlink" title="3. Presto 重要机制"></a>3. Presto 重要机制</h2><h3 id="3-1-多租户资源管理"><a href="#3-1-多租户资源管理" class="headerlink" title="3.1. 多租户资源管理"></a>3.1. 多租户资源管理</h3><p><strong>Resource Group</strong></p>
<ul>
<li>类似 Yarn 多级队列的资源管理方式</li>
<li>基于 CPU、MEMORY、SQL 执行数进行资源使用量限制</li>
<li>优点：轻量的 Query 级别的多级队列资源管理模式</li>
<li>缺点：存在一定的滞后性，只会对 Group 中正在运行的 SQL 进行判断</li>
</ul>
<p><strong>物理计划生成</strong></p>
<ol>
<li>Antlr4 解析生成 AST</li>
<li>转换成 Logical Plan</li>
<li>按照是都存在 Shuffle（Exchange），切分成不同的 Stage（Fragment）</li>
</ol>
<h3 id="3-2-多租户下的任务调度"><a href="#3-2-多租户下的任务调度" class="headerlink" title="3.2. 多租户下的任务调度"></a>3.2. 多租户下的任务调度</h3><h4 id="Stage-调度"><a href="#Stage-调度" class="headerlink" title="Stage 调度"></a><strong>Stage 调度</strong></h4><ul>
<li><p>Stage 的调度策略</p>
<ul>
<li><p>AllAtOnceExecutionPolicy（同时调度）</p>
<p>延迟点，会存在任务空跑</p>
</li>
<li><p>PhasedExecutionPolicy（分阶段调度）不代表每个 stage 都分开调度，典型应用场景（join 查询）</p>
<ul>
<li>Build 端：游标构建用 join 的 hashtable</li>
<li>Probe 端：对用户左表数据进行探查，需要等待 build 端完成</li>
<li>build 端构建 hashtable 端时，probe 端一直在空跑的</li>
</ul>
<p>有一定延迟，节省部分资源</p>
</li>
</ul>
</li>
</ul>
<h4 id="Task-调度"><a href="#Task-调度" class="headerlink" title="Task 调度"></a><strong>Task 调度</strong></h4><ul>
<li>如何确定 Task 的数量<ul>
<li>Source：根据数据 meta 决定分配多少个节点</li>
<li>Fixed：hash partition count 确定，如集群节点数量</li>
<li>Sink：汇聚结果，一台机器</li>
<li>Scaled：无分区限制，可扩展，如 write 数据</li>
<li>Coordinator_only：只需要 coodinator 参与</li>
</ul>
</li>
<li>选择什么样的节点<ul>
<li>HARD_AFFINITY：计算、存储 Local 模式，保障计算与存储在同一节点，减少数据传输</li>
<li>SOFT_AFFINITY：基于某些特定算法，如一只  HASH 函数，常用于缓存场景，保证相似的 Task 调度到同一个 Worker</li>
<li>NO_PREFERENCE：随机选取，常用于普通的纯计算 Task</li>
</ul>
</li>
</ul>
<h4 id="Split-调度"><a href="#Split-调度" class="headerlink" title="Split 调度"></a><strong>Split 调度</strong></h4><ul>
<li>FIFO：顺序执行，绝对公平</li>
<li>优先级调度：快速响应</li>
</ul>
<h3 id="3-3-内存计算"><a href="#3-3-内存计算" class="headerlink" title="3.3. 内存计算"></a>3.3. 内存计算</h3><p><strong>Pipeline 化的数据处理</strong></p>
<p>Pipeline（按 LocalExchange 拆分）：</p>
<ul>
<li>Pipeline 的引入更好的实现算子间的并行</li>
<li>语义上保证了每个 Task 内的数据流式处理</li>
</ul>
<p><strong>Back Presure Mechanism</strong></p>
<ul>
<li>控制 split 生成流程</li>
<li>控制 operator 的执行</li>
</ul>
<ol>
<li>targetConcurrency auto-scale-out：定时检查，如果 OutputBuffers 使用率低于 0.5 （下游消费较快，需要提高生产速度），并发度 +1</li>
<li>sink.max-buffer-size 写入 buffer 的大小控制</li>
<li>exhange.max0buffer-size 读取 buffer 的大小控制</li>
</ol>
<p>达到最大值时 operator 会进入阻塞状态。</p>
<h3 id="3-4-多数据源联邦查询"><a href="#3-4-多数据源联邦查询" class="headerlink" title="3.4. 多数据源联邦查询"></a>3.4. 多数据源联邦查询</h3><p>将各个数据源进行统一的抽象，最后由 presto server 进行统一的物理执行</p>
<p><img src="/blog/images/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/image-20220803112330433.png" alt="image-20220803112330433"></p>
<p><strong>局限性</strong></p>
<ol>
<li>元数据管理与映射（每个 connector 管理一套数据服务）</li>
<li>谓词下推</li>
<li>数据源分片</li>
</ol>
<h2 id="4-性能优化实践"><a href="#4-性能优化实践" class="headerlink" title="4. 性能优化实践"></a>4. 性能优化实践</h2><p><strong>常用性能分析工具</strong></p>
<ul>
<li><p>Grfana：埋点、系统指标如 CPU、内存、网络等的可视化界面，时序化的数据显示</p>
</li>
<li><p>Java 相关指令</p>
<ul>
<li>Jstack 查看 Java 线程栈信息，排查是否有死锁，或者一场线程存在</li>
<li>JMX（Java Management Extensions）是一个为应用程序植入管理功能的框架， 常用来做一些监控指标的统计收集</li>
<li>JMAP &amp; GC 日志等等内存分析工具</li>
</ul>
</li>
<li><p>线上问题排查工具</p>
<ul>
<li>Arthas<ul>
<li>Watch</li>
<li>Trace</li>
</ul>
</li>
<li>Flame Figure&#x2F;火焰图：用于分析热点代码占用大量 CPU，从而导致服务性能下降的情况</li>
</ul>
</li>
<li><p>Presto UI</p>
<ul>
<li>Query 级别统计信息</li>
<li>Logical Plan</li>
<li>Stage、Task 信息</li>
<li>Worker 状态信息</li>
</ul>
</li>
</ul>
<p>优化实践</p>
<p><img src="/blog/images/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/image-20220803113852154.png" alt="image-20220803113852154"></p>
<p><img src="/blog/images/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/image-20220803114114211.png" alt="image-20220803114114211"></p>
<p><img src="/blog/images/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/image-20220803113946981.png" alt="image-20220803113946981"></p>
<p><img src="/blog/images/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/image-20220803114019886.png" alt="image-20220803114019886"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://the_ring.gitee.io/blog/2022/08/03/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/" data-id="cl79sj7gb0000zgutc1ewgjg7" data-title="Presto 架构原理与优化" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/big-data/" rel="tag">big data</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/presto/" rel="tag">presto</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-大数据-Shuffle-原理与实践" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/blog/2022/07/31/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/" class="article-date">
  <time class="dt-published" datetime="2022-07-31T06:40:30.000Z" itemprop="datePublished">2022-07-31</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/blog/2022/07/31/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/">大数据 Shuffle 原理与实践</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-Shuffle-概述"><a href="#1-Shuffle-概述" class="headerlink" title="1. Shuffle 概述"></a>1. Shuffle 概述</h2><p>在开源实现的 MapReduce 中，存在 Map、Shuffle、Reduce 三个阶段</p>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731144434308.png" alt="image-20220731144434308"></p>
<blockquote>
<p>map 阶段，在单机上进行的针对一小块数据的计算过程。</p>
<p>Shuffle 阶段，在 map 阶段的基础上，进行数据移动，为后续的 reduce 阶段做准备。</p>
<p>reduce 阶段，对移动后的继续进行处理，依然在单机上处理一小份数据。</p>
</blockquote>
<p>在 Spark 框架中，shuffle 是支撑 spark 进行大规模复杂数据处理的基石。</p>
<h2 id="2-Shuffle-的算子"><a href="#2-Shuffle-的算子" class="headerlink" title="2. Shuffle 的算子"></a>2. Shuffle 的算子</h2><p>Spark 中会产生的 Shuffle 的算子大概可以分为 4 类：</p>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731145215735.png" alt="image-20220731145215735"></p>
<p>Spark 中对 Shuffle 的抽象 - 宽依赖、窄依赖：</p>
<ul>
<li>窄依赖：父 RDD 的每个分片至多被子 RDD 中的一个分片所依赖。</li>
<li>宽依赖：父 RDD 中的分片可能被子 RDD 中的多个分片所依赖。</li>
</ul>
<p>算子内部依赖关系：</p>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731145855422.png" alt="image-20220731145855422"></p>
<h2 id="3-Shuffle-过程"><a href="#3-Shuffle-过程" class="headerlink" title="3. Shuffle 过程"></a>3. Shuffle 过程</h2><p>Shuffle 发展</p>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731150354283.png" alt="image-20220731150354283"></p>
<p><strong>Hash Shuffle</strong></p>
<ol>
<li><strong>写数据</strong>：每个 partition 会映射到一个独立的文件。</li>
<li><strong>写数据优化</strong>：每个 partition 会映射一个文件片段；</li>
</ol>
<p><strong>Sort Shuffle - 写数据</strong>：每个 task 生成一个包含所有 partition 数据的文件。</p>
<p><strong>Shuffle - 读数据</strong>：每个 reduce task 分别获取所有 map task 生成的属于自己的片段。</p>
<p>Shuffle 过程的触发流程</p>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731151009745.png" alt="image-20220731151009745"></p>
<p>Register Shuffle 时做的最重要的事情是根据不同条件创建不同的 Shuffle Handle</p>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731151211298.png" alt="image-20220731151211298"></p>
<p><strong>Writer 实现</strong></p>
<ul>
<li>BypassMergeShuffleWriter<ul>
<li>不需要排序，节省时间</li>
<li>写操作的时候会打开大量文件</li>
<li>类似于 HashShuffle</li>
</ul>
</li>
<li>UnsafeShuffleWriter<ul>
<li>使用类似内存页存储序列化数据</li>
<li>数据写入后不再反序列化</li>
<li>只根据 partition 排序 Long Array</li>
<li>数据不移动</li>
</ul>
</li>
<li>SortShuffleWriter<ul>
<li>支持 combine</li>
<li>需要 combine 时，使用 PartitionedAppendOnlyMap，本质是个 HashTable</li>
<li>不需要 combine 时，PartitionedPairBuffer 本质是个 array</li>
</ul>
</li>
</ul>
<p><strong>Reader 实现</strong></p>
<p>网络时序图</p>
<ul>
<li>使用基于 netty 的网络通信框架</li>
<li>位置信息记录在 MapOutputTracker 中</li>
<li>主要会发送两种类型的请求<ul>
<li>OpenBlocks 请求</li>
<li>Chunk 请求或 Stream 请求</li>
</ul>
</li>
</ul>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731152023085.png" alt="image-20220731152023085"></p>
<ul>
<li><p>ShuffleBlockFetchIterator</p>
<ul>
<li>区分 local 和 remote 节省网络消耗</li>
<li>防止 OOM<ul>
<li>maxBytesInflight</li>
<li>maxReqsInFlight</li>
<li>maxBlocksInFlightPerAddress</li>
<li>maxReqSizeShuffleToMem</li>
<li>maxAttemptsOnNettyOOM</li>
</ul>
</li>
</ul>
</li>
<li><p>External Shuffle Service</p>
<p>ESS 作为一个存在于每个结点上的 agent 为所有 Shuffle Reader 提供服务，从而优化了 Spark 作业的资源利用率，MapTask 在运行结束后可以正常退出。</p>
</li>
</ul>
<p>**Shuffle 优化使用的技术 **</p>
<ul>
<li><p>Zero Copy</p>
<p>DMA(Direct Memory Access)：直接存储器读取，是指外部设备不通过 CPU 而直接与系统内存交换数据的接口技术。</p>
</li>
<li><p>Netty Zero Copy</p>
<ul>
<li>可堆外内存，避免 JVM 堆内存到堆外内存的数据拷贝。</li>
<li>CompositeByteBuf、Unpooled.wrappedBuffer、ByteBuf.slice，可以合并、包装、切分数组，避免发生内存拷贝。</li>
<li>Netty 使用 FileRegion 实现文件传输，FileRegion 底层封装了 FileChanel#trasferTo() 方法，可以将文件缓冲区的数据直接传输到目标 Channel，避免内核缓冲区和用户态缓冲区之间的数据拷贝。</li>
</ul>
</li>
</ul>
<p><strong>常见问题</strong></p>
<ul>
<li>数据存储在本地，没有备份；</li>
<li>IO 并发：大量 RPC 请求（M*R）</li>
<li>IO 吞吐：随机读、写放大（3X）</li>
<li>GC 频繁，影响 NodeManager</li>
</ul>
<p><strong>Shuffle 优化</strong></p>
<ul>
<li><p>避免 Shuffle</p>
<ul>
<li>使用 broadcast 替代 join</li>
</ul>
</li>
<li><p>使用可以 map-side 预聚合的算子</p>
</li>
<li><p>参数优化</p>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731154214778.png" alt="image-20220731154214778"></p>
</li>
<li><p>Shuffle 倾斜优化</p>
<ul>
<li><p>影响：作业运行时间变长、Task OMM 导致作业失败。</p>
</li>
<li><p>处理方法</p>
<ul>
<li><p>提高并行度（优点：简单；缺点：只缓解、不根治）</p>
</li>
<li><p>AQE</p>
<p>根据 Shuffle 文件统计数目自动检测倾斜数据，将那些倾斜的分区打散成更小的子分区，然后各自进行 join</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="4-Push-Shuffle"><a href="#4-Push-Shuffle" class="headerlink" title="4. Push Shuffle"></a>4. Push Shuffle</h2><blockquote>
<p>Avg IO size 太小，造成了大量的随机 IO，严重影响磁盘的吞吐；</p>
<p>M*R 次读请求，造成大量的网络连接，影响稳定性</p>
</blockquote>
<p><strong>Magnet 实现原理</strong></p>
<ul>
<li>Spark driver 组件，协调整个的 Shuffle 操作。</li>
<li>map 任务的 shuffle writer 过程完成后，增加了一个额外的操作 push-merge，将数据复制一份推送到远程 shuffle 服务器上。</li>
<li>magnet shuffle service 是一个强化版的 ESS。将隶属于同一个的 shuffle partition 的  block，会在远程传到 magnet 后被 merge 到一个文件中。</li>
<li>reduce 任务从 magnet shuffle service 接收合并好的 shuffle 数据。</li>
<li>bitmap：存储已 merger 的 mapper id，防止重复 merge。</li>
<li>position offset：如果本次 block 没有正常 merge，可以恢复到上一个 block 的位置。</li>
<li>currentMapId：表示当前正在 append 的 block，保证每个 mapper 的 block 能依次 append。</li>
</ul>
<p><strong>Magnet 可靠性</strong></p>
<ul>
<li>如果 Map tash 输出的 block 没有成功 Push 到  magnet 上，并且反复重试仍然失败，则 reduce task 直接从 ESS 上拉取原始 block 数据。</li>
<li>如果 magnet 上的 block 因为重复或者冲突等原因，没有正常完成 merge 的过程，则 reduce task 直接拉取未完成 merge 的 block</li>
<li>如果 reduce 拉去已经 merge 好的 block 失败，则会直接拉取 merge 前的原始 block</li>
<li>本质上，magnet 中维护了两份 shuffle 数据的副本</li>
</ul>
<p><strong>Cloud Shuffle Servie 思想</strong></p>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731160707875.png" alt="image-20220731160707875"></p>
<p>**<strong>Cloud shuffle Service 架构</strong></p>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731160801532.png" alt="image-20220731160801532"></p>
<p><strong>Cloud shuffle Service 写入流程</strong></p>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731160948086.png" alt="image-20220731160948086"></p>
<p><strong>Cloud Shuffle Service AQE</strong></p>
<p>一个 partition 会最终对应到多个 Epoch file，每个 RPoch 目前设置是 512 MB</p>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731161344573.png" alt="image-20220731161344573"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://the_ring.gitee.io/blog/2022/07/31/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/" data-id="cl79sj7gq0008zgut3s207d1v" data-title="大数据 Shuffle 原理与实践" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/big-data/" rel="tag">big data</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/shuffle/" rel="tag">shuffle</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-Hexo + GiteeGithub 搭建个人博客" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/blog/2022/07/30/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/" class="article-date">
  <time class="dt-published" datetime="2022-07-30T14:35:50.000Z" itemprop="datePublished">2022-07-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/blog/2022/07/30/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/">Hexo + Gitee/Github 搭建个人博客</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="一、-安装-Node-js-和-Git"><a href="#一、-安装-Node-js-和-Git" class="headerlink" title="一、 安装 Node.js 和 Git"></a>一、 安装 Node.js 和 Git</h2><p><a target="_blank" rel="noopener" href="https://nodejs.org/en/">Node.js</a></p>
<p><img src="/blog/images/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/image-20220730210351312.png" alt="image-20220730210351312"></p>
<p><img src="/blog/images/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/image-20220730210427462.png" alt="image-20220730210427462"></p>
<p><img src="/blog/images/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/image-20220730210530475.png" alt="image-20220730210530475"></p>
<p>自动安装完成即可</p>
<p>可以验证一下是否安装成功</p>
<p><img src="/blog/images/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/image-20220730210635122.png" alt="image-20220730210635122"></p>
<blockquote>
<p>已经安装过 Git，就不演示了</p>
</blockquote>
<h2 id="二、安装-Hexo"><a href="#二、安装-Hexo" class="headerlink" title="二、安装 Hexo"></a>二、安装 Hexo</h2><h3 id="1-安装-Hexo"><a href="#1-安装-Hexo" class="headerlink" title="1. 安装 Hexo"></a>1. 安装 Hexo</h3><p>修改使用淘宝链接进行安装</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g cnpm --registry=https://registry.npm.taobao.org</span><br></pre></td></tr></table></figure>

<p>开始安装</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cnpm install -g hexo-cli</span><br></pre></td></tr></table></figure>

<p>安装后验证</p>
<p><img src="/blog/images/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/image-20220730211707199.png" alt="image-20220730211707199"></p>
<h3 id="2-初始化"><a href="#2-初始化" class="headerlink" title="2. 初始化"></a>2. 初始化</h3><p>使用</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo init</span><br></pre></td></tr></table></figure>

<blockquote>
<p>先创建一个目录用来保存 blog，再在此目录下执行此命令</p>
</blockquote>
<p><img src="/blog/images/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/image-20220730212126969.png" alt="image-20220730212126969"></p>
<h3 id="3-启动"><a href="#3-启动" class="headerlink" title="3. 启动"></a>3. 启动</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo s</span><br></pre></td></tr></table></figure>

<p><img src="/blog/images/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/image-20220730212441470.png" alt="image-20220730212441470"></p>
<p>浏览器中使用 localhost:4000 即可访问</p>
<p><img src="/blog/images/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/image-20220730212408521.png" alt="image-20220730212408521"></p>
<h2 id="三、-部署到-Gitee-x2F-Github"><a href="#三、-部署到-Gitee-x2F-Github" class="headerlink" title="三、 部署到 Gitee&#x2F;Github"></a>三、 部署到 Gitee&#x2F;Github</h2><p>这里使用 Gitee 进行演示</p>
<h3 id="1-Gitee-上创建一个仓库"><a href="#1-Gitee-上创建一个仓库" class="headerlink" title="1. Gitee 上创建一个仓库"></a>1. Gitee 上创建一个仓库</h3><p><img src="/blog/images/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/image-20220730213227646.png" alt="image-20220730213227646"></p>
<h3 id="2-安装-Git-部署插件"><a href="#2-安装-Git-部署插件" class="headerlink" title="2. 安装 Git 部署插件"></a>2. 安装 Git 部署插件</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cnpm install --save hexo-deployer-git</span><br></pre></td></tr></table></figure>



<h3 id="3-修改配置"><a href="#3-修改配置" class="headerlink" title="3. 修改配置"></a>3. 修改配置</h3><p>打开安装目录的 <code>_config.yaml</code> 文件</p>
<p>添加以下内容</p>
<p><img src="/blog/images/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/image-20220730214249131.png" alt="image-20220730214249131"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://the_ring.gitee.io/blog/2022/07/30/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/" data-id="cl79sj7go0005zgutbdkr5fn8" data-title="Hexo + Gitee/Github 搭建个人博客" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/gitee/" rel="tag">gitee</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/github/" rel="tag">github</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/hexo/" rel="tag">hexo</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-hello-world" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/blog/2022/07/30/hello-world/" class="article-date">
  <time class="dt-published" datetime="2022-07-30T13:18:21.150Z" itemprop="datePublished">2022-07-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/blog/2022/07/30/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://the_ring.gitee.io/blog/2022/07/30/hello-world/" data-id="cl79sj7gn0004zgutbtf75n99" data-title="Hello World" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/HBase/" rel="tag">HBase</a></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/HDFS/" rel="tag">HDFS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/Kafka/" rel="tag">Kafka</a></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/Pulsar/" rel="tag">Pulsar</a></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/bid-data/" rel="tag">bid data</a></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/big-data/" rel="tag">big data</a></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/gitee/" rel="tag">gitee</a></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/github/" rel="tag">github</a></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/hexo/" rel="tag">hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/presto/" rel="tag">presto</a></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/shuffle/" rel="tag">shuffle</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/blog/tags/HBase/" style="font-size: 10px;">HBase</a> <a href="/blog/tags/HDFS/" style="font-size: 15px;">HDFS</a> <a href="/blog/tags/Kafka/" style="font-size: 10px;">Kafka</a> <a href="/blog/tags/Pulsar/" style="font-size: 10px;">Pulsar</a> <a href="/blog/tags/bid-data/" style="font-size: 10px;">bid data</a> <a href="/blog/tags/big-data/" style="font-size: 20px;">big data</a> <a href="/blog/tags/gitee/" style="font-size: 10px;">gitee</a> <a href="/blog/tags/github/" style="font-size: 10px;">github</a> <a href="/blog/tags/hexo/" style="font-size: 10px;">hexo</a> <a href="/blog/tags/presto/" style="font-size: 10px;">presto</a> <a href="/blog/tags/shuffle/" style="font-size: 10px;">shuffle</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2022/08/">August 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2022/07/">July 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/blog/2022/08/26/%E4%BB%8E%20Kafka%20%E5%88%B0%20Pulsar%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/">从 Kafka 到 Pulsar：数据流演进之路</a>
          </li>
        
          <li>
            <a href="/blog/2022/08/09/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%20HBase%20%E5%AE%9E%E6%88%98/">深入浅出 HBase 实战</a>
          </li>
        
          <li>
            <a href="/blog/2022/08/05/HDFS%20%E9%AB%98%E5%8F%AF%E7%94%A8%E5%92%8C%E9%AB%98%E6%89%A9%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/">HDFS 高可用和高扩展机制分析</a>
          </li>
        
          <li>
            <a href="/blog/2022/08/05/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/">HDFS 原理与应用</a>
          </li>
        
          <li>
            <a href="/blog/2022/08/03/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/">Presto 架构原理与优化</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/blog/" class="mobile-nav-link">Home</a>
  
    <a href="/blog/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/blog/js/jquery-3.4.1.min.js"></script>



  
<script src="/blog/fancybox/jquery.fancybox.min.js"></script>




<script src="/blog/js/script.js"></script>





  </div>
</body>
</html>