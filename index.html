<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://the_ring.gitee.io/blog/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/blog/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/blog/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/blog/css/style.css">

  
    
<link rel="stylesheet" href="/blog/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 6.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/blog/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/blog/">Home</a>
        
          <a class="main-nav-link" href="/blog/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/blog/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://the_ring.gitee.io/blog"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-HDFS 高可用和高扩展机制分析" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/blog/2022/08/05/HDFS%20%E9%AB%98%E5%8F%AF%E7%94%A8%E5%92%8C%E9%AB%98%E6%89%A9%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/" class="article-date">
  <time class="dt-published" datetime="2022-08-05T05:08:36.000Z" itemprop="datePublished">2022-08-05</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/blog/2022/08/05/HDFS%20%E9%AB%98%E5%8F%AF%E7%94%A8%E5%92%8C%E9%AB%98%E6%89%A9%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/">HDFS 高可用和高扩展机制分析</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-元数据高可用"><a href="#1-元数据高可用" class="headerlink" title="1. 元数据高可用"></a>1. 元数据高可用</h2><p>高可用的衡量</p>
<p><img src="/blog/../images/HDFS%20%E9%AB%98%E5%8F%AF%E7%94%A8%E5%92%8C%E9%AB%98%E6%89%A9%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/image-20220805131626421.png" alt="image-20220805131626421"></p>
<p>可用性年化</p>
<p><img src="/blog/../images/HDFS%20%E9%AB%98%E5%8F%AF%E7%94%A8%E5%92%8C%E9%AB%98%E6%89%A9%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/image-20220805131730291.png" alt="image-20220805131730291"></p>
<p>高可用的形式</p>
<p>HDFS 设计中，采用了中心化的元数据管理节点 NameNode。NameNode 容易称为故障中的单点（sngle point of failure）。</p>
<p>HDFS NameNode 高可用架构</p>
<ul>
<li>组件介绍<ul>
<li>ActiveNamenode：主节点，提供服务，生产日志</li>
<li>StandbyNamenode：备节点，消费日志</li>
<li>Zookeeper：为自动选主剔红统一协调服务</li>
<li>BookKeeper：提供日志存储服务</li>
<li>ZKFC：NameNode 探活、触发主备切换</li>
<li>HA Client：提供了自动切换的客户端</li>
<li>edit log：操作日志</li>
</ul>
</li>
<li>围绕三个问题来看高可用<ul>
<li>节点状态如何更新</li>
<li>操作日志如何同步</li>
<li>如何做到自动切换</li>
</ul>
</li>
</ul>
<p><img src="/blog/../images/HDFS%20%E9%AB%98%E5%8F%AF%E7%94%A8%E5%92%8C%E9%AB%98%E6%89%A9%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/image-20220805132032154.png" alt="image-20220805132032154"></p>
<p>理论基础——状态机复制和日志</p>
<p>状态机复制是实现容错的常规方法，组件：状态机及其副本、变更日志、共识协议。</p>
<p>NameNode 操作日志的生产消费</p>
<p>NameNode 块状态维护</p>
<p>分布式协调组件——Zookeeper</p>
<p>自动主备切换流程</p>
<p>Server侧</p>
<ol>
<li>ZKFailvorController：作为外部组件，驱动 HDFS NameNode 的主备切换</li>
<li>轮询探活</li>
<li>脑裂问题</li>
<li>Fence 机制</li>
</ol>
<p>Client侧</p>
<p>核心机制：StandbyException</p>
<p>Client 自动处理</p>
<p>BookKeeper 架构</p>
<p>BookKeeper 存储日志</p>
<ul>
<li>低延迟</li>
<li>持久性</li>
<li>强一致性</li>
<li>读写高可用</li>
</ul>
<p>对比：日志系统和文件系统的复杂度</p>
<p>Quorum 机制</p>
<p>Quorum 机制：多副本一致性读写</p>
<p>场景：多副本对象存储，用版本号标识数据新旧</p>
<p>BookKeeper Quorum</p>
<p>Sloppy Quorum 机制</p>
<p>日志场景：顺序追加、只写</p>
<p>Write Quorum：写入副本数</p>
<p>Ack Quorum：响应副本数</p>
<p>BookKeeper Ensemble</p>
<p>Ensemble 机制</p>
<h2 id="2-数据存储高可用"><a href="#2-数据存储高可用" class="headerlink" title="2. 数据存储高可用"></a>2. 数据存储高可用</h2><p>回到单机存储——RAID</p>
<p>Redundant Array of Independent Disks</p>
<p>特点</p>
<ul>
<li>廉价</li>
<li>高性能</li>
<li>大容量</li>
<li>高可用</li>
</ul>
<p>RAID 方案讲解</p>
<p>RAID 0：条带化</p>
<p>RAID 1：冗余</p>
<p>RAID 3：容错校验</p>
<p>HDFS 多副本</p>
<p>HDFS 版本的 RAID 1</p>
<p>优点：</p>
<ul>
<li>读写路径简单</li>
<li>副本修复简单</li>
<li>高可用</li>
</ul>
<p>Erasure Coding 原理</p>
<p>HDFS 版本的 RAID 2&#x2F;3</p>
<p>业界常用 Reed Solomon 算法</p>
<p>HDFS Erasure Coding</p>
<p>HDFS 版本的 RAID 2</p>
<p>和多副本比较</p>
<ul>
<li>读写速度</li>
<li>成本</li>
<li>修复速度</li>
<li>读写路径的实现</li>
</ul>
<p>初始网络架构</p>
<p>Server：一台服务器</p>
<p>机架（Rack）：放服务器的架子</p>
<p>TOR（Top of Rack）机架顶部的交换机</p>
<p>POD（Point of Delivery）数据中心中的一个物理区域</p>
<p>数据中心（Data Center）：集中部署服务器的场所</p>
<p>副本放置策略——机架感知</p>
<p>一个 TOR 故障导致整个机架不可用</p>
<p>降低跨 rack 流量</p>
<p>trade-off：一个本地、一个远端</p>
<p>案例：HDFS 多机房实践</p>
<p>多机房解决问题</p>
<ul>
<li>容量问题</li>
<li>容灾问题</li>
</ul>
<p>HDFS 双机房放置设计</p>
<ul>
<li>写入时，每个数据块在两个机房至少各有一个副本，数据实时吸入到两个机房</li>
<li>读取时，有限读本地的副本，避免了大量的跨机房读取</li>
</ul>
<p>多机房容灾实践</p>
<p>多机房部署的组件</p>
<ul>
<li>Zookeeper</li>
<li>BookKeeper</li>
<li>NameNode</li>
<li>DataNode</li>
</ul>
<p>容灾期间的策略</p>
<ul>
<li>容灾期间，限制跨机房写入</li>
<li>容灾期间，限制跨机房副本复制</li>
</ul>
<h2 id="3-元数据高扩展性"><a href="#3-元数据高扩展性" class="headerlink" title="3. 元数据高扩展性"></a>3. 元数据高扩展性</h2><p>元数据节点扩展性的挑战</p>
<p>HDFS NameNode 是个集中式服务，部署在单个机器上，内存和磁盘的容量、CPUU 的计算力都不能无限扩展</p>
<p>scale up vs. scale out</p>
<ul>
<li>扩容单个服务器的能力</li>
<li>部署多个服务器来服务</li>
</ul>
<p>挑战</p>
<ul>
<li>米子空间分裂</li>
<li>DataNode 汇报</li>
<li>目录树结构本身复杂</li>
</ul>
<p>常见的 Scale Out 方案</p>
<p>KV 模型的系统可以使用 partition</p>
<ul>
<li>Redis</li>
<li>Kafka</li>
<li>MySQL（分库分表）</li>
</ul>
<p>三种数据路由方式：</p>
<ul>
<li>服务端侧</li>
<li>路由层</li>
<li>客户端侧</li>
</ul>
<p>社区解决方案——BlockPool</p>
<p>解决 DN 同时服务多组 NN 的问题</p>
<ul>
<li>同一个 block id 在不同的 NN 上出现</li>
</ul>
<p>文件服务分层</p>
<ul>
<li>Namespace</li>
<li>Block Storage</li>
</ul>
<p>用 blockpool 来区分 DN 的服务</p>
<ul>
<li>数据块存储</li>
<li>心跳和块上报</li>
</ul>
<p>社区解决方案——viewfs</p>
<p>Federation 结构：将多个不同集群组合起来，对外表现向一个集群一样</p>
<p>viewfs 通过在 client-side 的配置，指定不同的目录访问不同的 NameNode</p>
<p>局限性：运维复杂</p>
<p>字节跳动的 NNProxy</p>
<p>NNProxy 是字节字眼的 HDFS 代理层，提供了路由服务</p>
<p>NNProxy 主要实现了路由管理和 RPC 转发以及鉴权、限流、查询缓存等额外功能</p>
<p>NNProxy 路由规则保存</p>
<p>三种数据路由方式：</p>
<ul>
<li>服务端侧</li>
<li>路由层</li>
<li>客户端侧</li>
</ul>
<p>考虑点：扩展性、运维性</p>
<p>NNProxy 路由转发实现</p>
<p>路径最长匹配规则，可以进一步划分目录树</p>
<p>进一步思考：</p>
<ul>
<li>单个 NN 不会遇到瓶颈吗？</li>
<li>跨集群 rename</li>
</ul>
<p>案例：小文件问题</p>
<p>小文件问题（LSOF，lots of small files）：大小不到一个 HDFS Block 大小的文件过多</p>
<ul>
<li>NameNode 瓶颈</li>
<li>I&#x2F;O 变成小的随机 IO，数据访问变慢</li>
<li>计算任务启动慢</li>
</ul>
<p>解决方案：</p>
<ul>
<li>后台任务合并小文件</li>
<li>Shuffle Service</li>
</ul>
<h2 id="4-数据存储高扩展性"><a href="#4-数据存储高扩展性" class="headerlink" title="4. 数据存储高扩展性"></a>4. 数据存储高扩展性</h2><p>延迟的分布和长尾延迟</p>
<p>延迟的分布：</p>
<ul>
<li>用百分数来表示发个文的延迟的统计特征</li>
<li>例如 p95 延迟 1,s，代表 95% 的请求延迟要低于 1ms，但后 5% 的请求延迟会大于 1ms</li>
</ul>
<p>长尾延迟：尾部（p99&#x2F;p999&#x2F;p9999）的延迟，衡量系统最差的请求情况，会显著的要差于平均值</p>
<p>尾部延迟放大</p>
<p>木桶原理：尾部延迟放大：访问的服务变多，尾部的请求就会越发的慢</p>
<p>如何变慢</p>
<ul>
<li>固定延迟阈值</li>
<li>固定延迟百分位</li>
</ul>
<p>长尾问题的表现——慢节点</p>
<p>慢节点：读取速度过慢，导致客户端阻塞</p>
<p>慢节点的发生难以避免和预测</p>
<ul>
<li>共享资源、后台维护活动、请求多级排队、功率限制</li>
<li>固定的损耗：机器损坏率</li>
<li>混沌问题</li>
</ul>
<p>离线任务也会遇到长尾问题</p>
<ul>
<li>全部任务完成时间取决于最慢的任务什么时候完成</li>
<li>集群规模变大，任务的数据量变大</li>
<li>只要任何数据块的读取受到长尾影响，整个任务就会因此停滞</li>
</ul>
<p>集群扩大 10 倍，问题扩大 N（&gt;10）倍</p>
<p>超大集群下的数据可靠性</p>
<ul>
<li>条件一：超大集群下，有一部分机器损坏来不及修理的。</li>
<li>条件二：副本放置策略完全随机</li>
<li>条件三：DN 容量足够大</li>
</ul>
<p>推论：必然有部分数据全部副本在损坏的机器上，发生数据丢失</p>
<p>估算：三副本，10000 台机器，每台一百万副本。</p>
<ul>
<li>有多少种放置组合数</li>
<li>损坏 100 台机器，会有多少副本丢失</li>
</ul>
<p>叠加长尾问题，容易导致整个任务无法执行下去</p>
<p>Copyset</p>
<p>将 DataNode 分为若干个 Copyset 选块在 Copyset 内部选择</p>
<p>原理：减少了副本放置的组合数，从而降低副本丢失的概率</p>
<p>超大集群的负载均衡和数据迁移</p>
<p><img src="/blog/../images/HDFS%20%E9%AB%98%E5%8F%AF%E7%94%A8%E5%92%8C%E9%AB%98%E6%89%A9%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/image-20220805143659568.png" alt="image-20220805143659568"></p>
<p>数据写入&#x2F;读取不均</p>
<p>数据的不均匀</p>
<ul>
<li>节点容量不均匀</li>
<li>数据新旧不均匀</li>
<li>访问类型不均匀</li>
</ul>
<p>资源负载不均匀</p>
<p>负载均衡和数据迁移的典型场景</p>
<p><img src="/blog/../images/HDFS%20%E9%AB%98%E5%8F%AF%E7%94%A8%E5%92%8C%E9%AB%98%E6%89%A9%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/image-20220805143930787.png" alt="image-20220805143930787"></p>
<p>数据迁移工具——跨 NN 迁移</p>
<p>DistCopy</p>
<ul>
<li>基于 MapReduce，通过一个个任务，将数据从一个 NameNode 拷贝到另一个 NameNode</li>
<li>需要拷贝数据，流量较大，速度较慢</li>
</ul>
<p>FastCopy</p>
<ul>
<li>开源社区的无需拷贝数据的源数据迁移方案</li>
<li>前提条件：新旧集群的 DN 列表吻合</li>
<li>对于元数据，直接复制目录树的结构和块信息</li>
<li>对于数据块，直接要求 DataNode 从源 BlockPool hardlink 到目标 BlookPool，没有数据拷贝</li>
<li>hardlink：直接让两个路径指向同一个块数据</li>
</ul>
<p>数据迁移工具——Balancer</p>
<p>工具向 DataNode 发起迁移指令，平衡各个 DataNode 的容量</p>
<p>场景：</p>
<ul>
<li>单机房使用、多机房使用</li>
<li>限流措施</li>
</ul>
<p>评价标准</p>
<ul>
<li>稳定性成本</li>
<li>可运维性</li>
<li>执行效率</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://the_ring.gitee.io/blog/2022/08/05/HDFS%20%E9%AB%98%E5%8F%AF%E7%94%A8%E5%92%8C%E9%AB%98%E6%89%A9%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/" data-id="cl6g3rxvz0001g4ut7era0ior" data-title="HDFS 高可用和高扩展机制分析" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/HDFS/" rel="tag">HDFS</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/big-data/" rel="tag">big data</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-HDFS 原理与应用" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/blog/2022/08/05/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/" class="article-date">
  <time class="dt-published" datetime="2022-08-05T04:05:10.000Z" itemprop="datePublished">2022-08-05</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/blog/2022/08/05/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/">HDFS 原理与应用</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-HDFS-基本介绍"><a href="#1-HDFS-基本介绍" class="headerlink" title="1. HDFS 基本介绍"></a>1. HDFS 基本介绍</h2><p>Windows 文件系统：NTFS</p>
<p>Linux 文件系统：BTRFS、ZFS、XFS、EXT4</p>
<p>分布式文件系统：大容量（更多的机器，更多的存储介质）、高可靠（多个副本提高容错能力）、低成本（不需要高端硬件来扩容）</p>
<p><img src="/blog/images/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/image-20220805121036274.png" alt="image-20220805121036274"></p>
<h4 id="HDFS-功能特性："><a href="#HDFS-功能特性：" class="headerlink" title="HDFS 功能特性："></a>HDFS 功能特性：</h4><ol>
<li>分布式：受 GFS 启发，用 Java 实现的开源系统，没有实现完整的 POSIX 文件系统的语义</li>
<li>容错：自动处理，规避多种错误场景，例如常见的网络错误、机器宕机等</li>
<li>高可用：一主多备模式实现袁术高可用，数据多副本实现用户数据的高可用</li>
<li>高吞吐：Client 直接从 DataNode 读取用户数据，服务端支持海量 Client 读写</li>
<li>可扩展：支持联邦集群模式，DataNode 数量高达 10W 级别</li>
<li>廉价：只需要通用硬件，不需要定制高端的昂贵硬件设备</li>
</ol>
<h2 id="2-架构原理"><a href="#2-架构原理" class="headerlink" title="2. 架构原理"></a>2. 架构原理</h2><h4 id="Client-写流程："><a href="#Client-写流程：" class="headerlink" title="Client 写流程："></a>Client 写流程：</h4><p><img src="/blog/images/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/image-20220805121752901.png" alt="image-20220805121752901"></p>
<h4 id="Client-读流程："><a href="#Client-读流程：" class="headerlink" title="Client 读流程："></a>Client 读流程：</h4><p><img src="/blog/images/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/image-20220805121944362.png" alt="image-20220805121944362"></p>
<h4 id="元数据节点-NameNode："><a href="#元数据节点-NameNode：" class="headerlink" title="元数据节点 NameNode："></a>元数据节点 NameNode：</h4><ul>
<li><strong>维护目录树</strong>：维护目录树的增删改查，保证所有数据修改都能持久化，以便机器掉电不会造成数据丢失或不一致。</li>
<li><strong>维护文件和数据块的关系</strong>：文件被切分成多个快，文件以数据快为单位进行多副本存放。</li>
<li><strong>维护文件快存放节点信息</strong>：通过接收 DataNode 的心跳汇报信息，维护集群节点的拓扑结构和每个文件块所有副本所在的 DataNode 类表。</li>
<li><strong>分配新文件存放节点</strong>：Client 创建新的文件时，需要 NameNode 来确定目标 DataNode。</li>
</ul>
<h4 id="数据节点-DataNode："><a href="#数据节点-DataNode：" class="headerlink" title="数据节点 DataNode："></a>数据节点 DataNode：</h4><ul>
<li><strong>数据块存取</strong>：DataNode 需要高效实现对数据块在硬盘上的存取。</li>
<li><strong>心跳汇报</strong>：把存放在本机的数据块发送给 NameNode，以便 NameNode 能维护数据块的位置信息，同时让 NameNode 确定该节点处于正常存活状态。</li>
<li><strong>副本复制</strong>：数据写入时 Pipeline IO 操作；机器故障时补全副本。</li>
</ul>
<h2 id="3-关键设计"><a href="#3-关键设计" class="headerlink" title="3. 关键设计"></a>3. 关键设计</h2><h4 id="分布式存储系统基本概念："><a href="#分布式存储系统基本概念：" class="headerlink" title="分布式存储系统基本概念："></a>分布式存储系统基本概念：</h4><ol>
<li><strong>容错能力</strong>：能够让绝大部分异常场景，例如服务器当即、网络异常、硬盘故障、网络超时等。</li>
<li><strong>一致性模型</strong>：为了实现容错，数据必须多副本存放，一致性要解决的问题是如何保障多个副本的内容都是一致的。</li>
<li><strong>可扩展性</strong>：分布式存储系统需要具备横向扩张 scale-out 的能力。</li>
<li><strong>节点体系</strong>：常见的有主从模式、对等模式，不管哪种模式，高可用是必须的功能。</li>
<li><strong>数据放置</strong>：系统是由多个节点组成，数据是多个副本存放时，需要考虑存放的策略。</li>
<li><strong>单机存储引擎</strong>：在绝大多数存储系统中，数据都是需要落盘持久化，单机引擎需要解决的是根据系统特点，如何高效地存取硬盘数据。</li>
</ol>
<h4 id="NameNode-目录是维护"><a href="#NameNode-目录是维护" class="headerlink" title="NameNode 目录是维护"></a>NameNode 目录是维护</h4><ul>
<li>fsimage<ul>
<li>文件系统目录树</li>
<li>完整的存放在内存</li>
<li>定时存放到硬盘上</li>
<li>修改时指挥修改内存中的目录树</li>
</ul>
</li>
<li>EditLog<ul>
<li>目录树的修改日志</li>
<li>client 更新目录树需要持久化 EditLog 后才能表示更新成功</li>
<li>EditLog 可存放在本地文件系统，也可存放在专用系统上</li>
<li>NameNode HA 方案一贯关键点就是如何实现 EditLog 共享</li>
</ul>
</li>
</ul>
<h4 id="NameNode-数据放置"><a href="#NameNode-数据放置" class="headerlink" title="NameNode 数据放置"></a>NameNode 数据放置</h4><ul>
<li>数据快信息维护<ul>
<li>目录树保存了每个文件的块 id</li>
<li>NameNode 维护了每个数据块所在的节点信息</li>
<li>NameNode 根据 DataNode 汇报的信息动态维护位置信息</li>
<li>NameNode 不会持久化数据块位置信息</li>
</ul>
</li>
<li>数据块放置策略<ul>
<li>新数据存放到哪个写节点</li>
<li>数据均衡需要怎么合理搬迁数据</li>
<li>3 个副本怎么合理放置</li>
</ul>
</li>
</ul>
<h4 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h4><ul>
<li>数据块的硬盘存放<ul>
<li>文件在 NameNode 已分割成 block</li>
<li>DateNode 以 block 为单位对数据进行存取</li>
</ul>
</li>
<li>启动扫盘<ul>
<li>DataNode 需要知道本机存放了哪些数据块</li>
<li>启动时把本机硬盘上的数据块列表加载在内存中</li>
</ul>
</li>
</ul>
<h4 id="HDFS-写异常处理"><a href="#HDFS-写异常处理" class="headerlink" title="HDFS 写异常处理"></a>HDFS 写异常处理</h4><p><strong>情景</strong>：文件写了一半，client 自己挂掉了。可能产生的问题：</p>
<ul>
<li>副本不一致</li>
<li>Lease 无法释放</li>
</ul>
<p><strong>租约</strong>：Client 要修改一个文件，需要通过 NameNode 上锁，这个所就是租约（Lease）</p>
<p><strong>解决办法</strong>：Lease Recovery</p>
<p><strong>情景</strong>：文件写入过程中，DataNode 侧出现异常挂掉了。</p>
<p><strong>异常出现的时机</strong>：</p>
<ul>
<li>创建连接时</li>
<li>数据传输时</li>
<li>complete 阶段</li>
</ul>
<p><strong>解决办法</strong>：Pipeline Recovery</p>
<h4 id="HDFS-读异常处理"><a href="#HDFS-读异常处理" class="headerlink" title="HDFS 读异常处理"></a>HDFS 读异常处理</h4><p><strong>情景</strong>：读取文件的过程，DataNode 侧出现异常挂掉了</p>
<p><strong>解决办法</strong>：节点 Failover</p>
<p><strong>增强情景</strong>：节点半死不过，读取很慢</p>
<h4 id="旁路系统"><a href="#旁路系统" class="headerlink" title="旁路系统"></a>旁路系统</h4><p><strong>Balancer</strong>：均衡 DataNode 的容量</p>
<p><strong>Mover</strong>：确保副本放置符合策略要求</p>
<h4 id="控制面建设"><a href="#控制面建设" class="headerlink" title="控制面建设"></a>控制面建设</h4><p><strong>可观测性设施</strong>：</p>
<ul>
<li>指标埋点</li>
<li>数据采集</li>
<li>访问日志</li>
<li>数据分析</li>
</ul>
<p><strong>运维体系建设</strong></p>
<ul>
<li>运维操作需要平台化</li>
<li>NameNode 操作复杂</li>
<li>DataNode 机器规模庞大</li>
<li>组件控制面 API</li>
</ul>
<h2 id="4-应用场景"><a href="#4-应用场景" class="headerlink" title="4. 应用场景"></a>4. 应用场景</h2><h4 id="ETL"><a href="#ETL" class="headerlink" title="ETL"></a>ETL</h4><p><img src="/blog/images/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/image-20220805130350452.png" alt="image-20220805130350452"></p>
<h4 id="OLAP-查询引擎"><a href="#OLAP-查询引擎" class="headerlink" title="OLAP 查询引擎"></a>OLAP 查询引擎</h4><p><img src="/blog/images/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/image-20220805130455511.png" alt="image-20220805130455511"></p>
<h4 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h4><p><img src="/blog/images/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/image-20220805130530917.png" alt="image-20220805130530917"></p>
<h4 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h4><p><img src="/blog/images/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/image-20220805130609707.png" alt="image-20220805130609707"></p>
<h4 id="通用存储应用"><a href="#通用存储应用" class="headerlink" title="通用存储应用"></a>通用存储应用</h4><p><img src="/blog/images/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/image-20220805130649802.png" alt="image-20220805130649802"></p>
<blockquote>
<p>MIT 8.624</p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://the_ring.gitee.io/blog/2022/08/05/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/" data-id="cl6g3rxvu0000g4ut7o6xg7u0" data-title="HDFS 原理与应用" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/HDFS/" rel="tag">HDFS</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/big-data/" rel="tag">big data</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-Presto 架构原理与优化介绍" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/blog/2022/08/03/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/" class="article-date">
  <time class="dt-published" datetime="2022-08-03T02:10:10.000Z" itemprop="datePublished">2022-08-03</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/blog/2022/08/03/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/">Presto 架构原理与优化</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><h3 id="1-1-大数据与-OLAP-的演进"><a href="#1-1-大数据与-OLAP-的演进" class="headerlink" title="1.1. 大数据与 OLAP 的演进"></a>1.1. 大数据与 OLAP 的演进</h3><p>OLAP（OnLine Analytical Processing）对业务数据执行多维分析，并提供复杂计算，趋势分析和复杂数据建模的能力。是许多商务智能（BI）应用程序背后的技术。</p>
<p>OLAP 核心概念：维度、度量</p>
<p>常见的  OLAP 引擎：</p>
<ul>
<li>与计算引擎：Kylin、Druid</li>
<li>批式处理引擎：Hive、Saprk</li>
<li>流式处理引擎：Flink</li>
<li>交互式处理引擎：Presto、Clickhosue、Doris</li>
</ul>
<h3 id="1-2-Presto-设计思想"><a href="#1-2-Presto-设计思想" class="headerlink" title="1.2. Presto 设计思想"></a>1.2. Presto 设计思想</h3><p>Presto 最初由 Facebook 研发的构建于 Hadoop&#x2F;HDFS 系统之上的 PB 集交互式分析引擎，具有以下特点：</p>
<ul>
<li>多租户任务的管理与调度</li>
<li>多数据源联邦查询</li>
<li>支持内存优化计算</li>
<li>Pipline 式数据处理</li>
</ul>
<h2 id="2-Presto-基础原理和概念"><a href="#2-Presto-基础原理和概念" class="headerlink" title="2. Presto 基础原理和概念"></a>2. Presto 基础原理和概念</h2><h3 id="2-1-基础原理与概念"><a href="#2-1-基础原理与概念" class="headerlink" title="2.1. 基础原理与概念"></a>2.1. 基础原理与概念</h3><p><strong>服务相关</strong></p>
<p><img src="/blog/images/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/image-20220803102720230.png" alt="image-20220803102720230"></p>
<ul>
<li>Coordinator<ul>
<li>解析 SQL 语句</li>
<li>生成执行计划</li>
<li>分发执行任务给 Worker 节点</li>
</ul>
</li>
<li>Worker<ul>
<li>执行 Task 处理数据</li>
<li>与其他 Worker 交互传输数据</li>
</ul>
</li>
</ul>
<p><strong>数据源相关</strong></p>
<p><img src="/blog/images/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/image-20220803103002056.png" alt="image-20220803103002056"></p>
<ul>
<li>Connector：一个 Connector 代表一种数据源，可以认为 Connector 是由 Presto 提供的适配多数据源的统一接口。</li>
<li>Catalog：管理员辕信息与实际数据的映射关系。</li>
</ul>
<p><strong>Query 相关</strong></p>
<ul>
<li>Query：基于 SQL parser 后获得的执行计划。</li>
<li>Stage：根据是否需要 shuffle 将 Query 拆分成不同的 subplan，欸一个 subplan 是一个 stage。</li>
<li>Fragment：基本等价于 stage，属于不同阶段的称呼。</li>
<li>Task：单个 Worker 节点上的最小资源管理单元，在一个节点上，一个 Stage 只有一个 Task，一个 Query 可能有多个 Task。</li>
<li>Pipeline：Stage 按照 LocalExchange 切分为若干 Operator 集合，每个 Operator 集合定义一个 Pipeline。</li>
<li>Driver：Pipeline 的可执行实体，Pipeline 和 Driver 的关系可类比为程序和进程，是最小的执行单元，通过火山迭代模型执行每一个 Operator。</li>
<li>Split：输入数据描述（数据实体是 Page)，数量上和 Driver 一一对应，不仅代表实际数据源 split，也代表了不同 stage 间传输的数据。</li>
<li>Operator：最小物理算子。</li>
</ul>
<p><strong>数据传输相关</strong></p>
<ul>
<li>Exchange：表示不同 Stage 间的数据传输，大多数意义下等价于 Shuffle。</li>
<li>LocalExchange：Stage 内的 rehash 操作，常用于提高并行处理数据的能力（Task 在 Presto 中只是最小的容器，而不是最小的执行单元），<u>默认值是16</u>。</li>
</ul>
<h3 id="2-2-核心组件结构介绍"><a href="#2-2-核心组件结构介绍" class="headerlink" title="2.2. 核心组件结构介绍"></a>2.2. 核心组件结构介绍</h3><p><strong>Presto 结构图</strong></p>
<p><img src="/blog/images/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/image-20220803104359902.png" alt="image-20220803104359902"></p>
<p><strong>服务发现</strong></p>
<p>Discovery Service：</p>
<ol>
<li>Worker 配置文件配置 Discovery Service 地址</li>
<li>Worker 节点启动后会向 Discovery Service 注册</li>
<li>Coordinator 从 Discovery Service 获取 Worker 的地址</li>
</ol>
<p><strong>通信机制</strong></p>
<ul>
<li><p>通信机制</p>
<ol>
<li>Presto Client &#x2F; JDBC Client 与 Server 间通信 —- htpp</li>
<li>Coordinator 与 Worker 间的通信 —- Thrift&#x2F;Http</li>
<li>Worker 与 Worker 间的通信 —- Thrift&#x2F;Http</li>
</ol>
<blockquote>
<p>Thrift 具有更好的数据编码能力，Http 1.1 还不支持头部信息的压缩，Thrift 具有更好的数据压缩能力</p>
</blockquote>
</li>
<li><p>节点状态</p>
<ul>
<li>ACTIVE</li>
<li>INACTIVE</li>
<li>SHUTDOWN</li>
</ul>
</li>
</ul>
<h2 id="3-Presto-重要机制"><a href="#3-Presto-重要机制" class="headerlink" title="3. Presto 重要机制"></a>3. Presto 重要机制</h2><h3 id="3-1-多租户资源管理"><a href="#3-1-多租户资源管理" class="headerlink" title="3.1. 多租户资源管理"></a>3.1. 多租户资源管理</h3><p><strong>Resource Group</strong></p>
<ul>
<li>类似 Yarn 多级队列的资源管理方式</li>
<li>基于 CPU、MEMORY、SQL 执行数进行资源使用量限制</li>
<li>优点：轻量的 Query 级别的多级队列资源管理模式</li>
<li>缺点：存在一定的滞后性，只会对 Group 中正在运行的 SQL 进行判断</li>
</ul>
<p><strong>物理计划生成</strong></p>
<ol>
<li>Antlr4 解析生成 AST</li>
<li>转换成 Logical Plan</li>
<li>按照是都存在 Shuffle（Exchange），切分成不同的 Stage（Fragment）</li>
</ol>
<h3 id="3-2-多租户下的任务调度"><a href="#3-2-多租户下的任务调度" class="headerlink" title="3.2. 多租户下的任务调度"></a>3.2. 多租户下的任务调度</h3><h4 id="Stage-调度"><a href="#Stage-调度" class="headerlink" title="Stage 调度"></a><strong>Stage 调度</strong></h4><ul>
<li><p>Stage 的调度策略</p>
<ul>
<li><p>AllAtOnceExecutionPolicy（同时调度）</p>
<p>延迟点，会存在任务空跑</p>
</li>
<li><p>PhasedExecutionPolicy（分阶段调度）不代表每个 stage 都分开调度，典型应用场景（join 查询）</p>
<ul>
<li>Build 端：游标构建用 join 的 hashtable</li>
<li>Probe 端：对用户左表数据进行探查，需要等待 build 端完成</li>
<li>build 端构建 hashtable 端时，probe 端一直在空跑的</li>
</ul>
<p>有一定延迟，节省部分资源</p>
</li>
</ul>
</li>
</ul>
<h4 id="Task-调度"><a href="#Task-调度" class="headerlink" title="Task 调度"></a><strong>Task 调度</strong></h4><ul>
<li>如何确定 Task 的数量<ul>
<li>Source：根据数据 meta 决定分配多少个节点</li>
<li>Fixed：hash partition count 确定，如集群节点数量</li>
<li>Sink：汇聚结果，一台机器</li>
<li>Scaled：无分区限制，可扩展，如 write 数据</li>
<li>Coordinator_only：只需要 coodinator 参与</li>
</ul>
</li>
<li>选择什么样的节点<ul>
<li>HARD_AFFINITY：计算、存储 Local 模式，保障计算与存储在同一节点，减少数据传输</li>
<li>SOFT_AFFINITY：基于某些特定算法，如一只  HASH 函数，常用于缓存场景，保证相似的 Task 调度到同一个 Worker</li>
<li>NO_PREFERENCE：随机选取，常用于普通的纯计算 Task</li>
</ul>
</li>
</ul>
<h4 id="Split-调度"><a href="#Split-调度" class="headerlink" title="Split 调度"></a><strong>Split 调度</strong></h4><ul>
<li>FIFO：顺序执行，绝对公平</li>
<li>优先级调度：快速响应</li>
</ul>
<h3 id="3-3-内存计算"><a href="#3-3-内存计算" class="headerlink" title="3.3. 内存计算"></a>3.3. 内存计算</h3><p><strong>Pipeline 化的数据处理</strong></p>
<p>Pipeline（按 LocalExchange 拆分）：</p>
<ul>
<li>Pipeline 的引入更好的实现算子间的并行</li>
<li>语义上保证了每个 Task 内的数据流式处理</li>
</ul>
<p><strong>Back Presure Mechanism</strong></p>
<ul>
<li>控制 split 生成流程</li>
<li>控制 operator 的执行</li>
</ul>
<ol>
<li>targetConcurrency auto-scale-out：定时检查，如果 OutputBuffers 使用率低于 0.5 （下游消费较快，需要提高生产速度），并发度 +1</li>
<li>sink.max-buffer-size 写入 buffer 的大小控制</li>
<li>exhange.max0buffer-size 读取 buffer 的大小控制</li>
</ol>
<p>达到最大值时 operator 会进入阻塞状态。</p>
<h3 id="3-4-多数据源联邦查询"><a href="#3-4-多数据源联邦查询" class="headerlink" title="3.4. 多数据源联邦查询"></a>3.4. 多数据源联邦查询</h3><p>将各个数据源进行统一的抽象，最后由 presto server 进行统一的物理执行</p>
<p><img src="/blog/images/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/image-20220803112330433.png" alt="image-20220803112330433"></p>
<p><strong>局限性</strong></p>
<ol>
<li>元数据管理与映射（每个 connector 管理一套数据服务）</li>
<li>谓词下推</li>
<li>数据源分片</li>
</ol>
<h2 id="4-性能优化实践"><a href="#4-性能优化实践" class="headerlink" title="4. 性能优化实践"></a>4. 性能优化实践</h2><p><strong>常用性能分析工具</strong></p>
<ul>
<li><p>Grfana：埋点、系统指标如 CPU、内存、网络等的可视化界面，时序化的数据显示</p>
</li>
<li><p>Java 相关指令</p>
<ul>
<li>Jstack 查看 Java 线程栈信息，排查是否有死锁，或者一场线程存在</li>
<li>JMX（Java Management Extensions）是一个为应用程序植入管理功能的框架， 常用来做一些监控指标的统计收集</li>
<li>JMAP &amp; GC 日志等等内存分析工具</li>
</ul>
</li>
<li><p>线上问题排查工具</p>
<ul>
<li>Arthas<ul>
<li>Watch</li>
<li>Trace</li>
</ul>
</li>
<li>Flame Figure&#x2F;火焰图：用于分析热点代码占用大量 CPU，从而导致服务性能下降的情况</li>
</ul>
</li>
<li><p>Presto UI</p>
<ul>
<li>Query 级别统计信息</li>
<li>Logical Plan</li>
<li>Stage、Task 信息</li>
<li>Worker 状态信息</li>
</ul>
</li>
</ul>
<p>优化实践</p>
<p><img src="/blog/images/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/image-20220803113852154.png" alt="image-20220803113852154"></p>
<p><img src="/blog/images/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/image-20220803114114211.png" alt="image-20220803114114211"></p>
<p><img src="/blog/images/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/image-20220803113946981.png" alt="image-20220803113946981"></p>
<p><img src="/blog/images/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/image-20220803114019886.png" alt="image-20220803114019886"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://the_ring.gitee.io/blog/2022/08/03/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/" data-id="cl6g3rxw30004g4ut1qoc5qk6" data-title="Presto 架构原理与优化" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/big-data/" rel="tag">big data</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/presto/" rel="tag">presto</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-大数据-Shuffle-原理与实践" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/blog/2022/07/31/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/" class="article-date">
  <time class="dt-published" datetime="2022-07-31T06:40:30.000Z" itemprop="datePublished">2022-07-31</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/blog/2022/07/31/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/">大数据 Shuffle 原理与实践</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-Shuffle-概述"><a href="#1-Shuffle-概述" class="headerlink" title="1. Shuffle 概述"></a>1. Shuffle 概述</h2><p>在开源实现的 MapReduce 中，存在 Map、Shuffle、Reduce 三个阶段</p>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731144434308.png" alt="image-20220731144434308"></p>
<blockquote>
<p>map 阶段，在单机上进行的针对一小块数据的计算过程。</p>
<p>Shuffle 阶段，在 map 阶段的基础上，进行数据移动，为后续的 reduce 阶段做准备。</p>
<p>reduce 阶段，对移动后的继续进行处理，依然在单机上处理一小份数据。</p>
</blockquote>
<p>在 Spark 框架中，shuffle 是支撑 spark 进行大规模复杂数据处理的基石。</p>
<h2 id="2-Shuffle-的算子"><a href="#2-Shuffle-的算子" class="headerlink" title="2. Shuffle 的算子"></a>2. Shuffle 的算子</h2><p>Spark 中会产生的 Shuffle 的算子大概可以分为 4 类：</p>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731145215735.png" alt="image-20220731145215735"></p>
<p>Spark 中对 Shuffle 的抽象 - 宽依赖、窄依赖：</p>
<ul>
<li>窄依赖：父 RDD 的每个分片至多被子 RDD 中的一个分片所依赖。</li>
<li>宽依赖：父 RDD 中的分片可能被子 RDD 中的多个分片所依赖。</li>
</ul>
<p>算子内部依赖关系：</p>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731145855422.png" alt="image-20220731145855422"></p>
<h2 id="3-Shuffle-过程"><a href="#3-Shuffle-过程" class="headerlink" title="3. Shuffle 过程"></a>3. Shuffle 过程</h2><p>Shuffle 发展</p>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731150354283.png" alt="image-20220731150354283"></p>
<p><strong>Hash Shuffle</strong></p>
<ol>
<li><strong>写数据</strong>：每个 partition 会映射到一个独立的文件。</li>
<li><strong>写数据优化</strong>：每个 partition 会映射一个文件片段；</li>
</ol>
<p><strong>Sort Shuffle - 写数据</strong>：每个 task 生成一个包含所有 partition 数据的文件。</p>
<p><strong>Shuffle - 读数据</strong>：每个 reduce task 分别获取所有 map task 生成的属于自己的片段。</p>
<p>Shuffle 过程的触发流程</p>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731151009745.png" alt="image-20220731151009745"></p>
<p>Register Shuffle 时做的最重要的事情是根据不同条件创建不同的 Shuffle Handle</p>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731151211298.png" alt="image-20220731151211298"></p>
<p><strong>Writer 实现</strong></p>
<ul>
<li>BypassMergeShuffleWriter<ul>
<li>不需要排序，节省时间</li>
<li>写操作的时候会打开大量文件</li>
<li>类似于 HashShuffle</li>
</ul>
</li>
<li>UnsafeShuffleWriter<ul>
<li>使用类似内存页存储序列化数据</li>
<li>数据写入后不再反序列化</li>
<li>只根据 partition 排序 Long Array</li>
<li>数据不移动</li>
</ul>
</li>
<li>SortShuffleWriter<ul>
<li>支持 combine</li>
<li>需要 combine 时，使用 PartitionedAppendOnlyMap，本质是个 HashTable</li>
<li>不需要 combine 时，PartitionedPairBuffer 本质是个 array</li>
</ul>
</li>
</ul>
<p><strong>Reader 实现</strong></p>
<p>网络时序图</p>
<ul>
<li>使用基于 netty 的网络通信框架</li>
<li>位置信息记录在 MapOutputTracker 中</li>
<li>主要会发送两种类型的请求<ul>
<li>OpenBlocks 请求</li>
<li>Chunk 请求或 Stream 请求</li>
</ul>
</li>
</ul>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731152023085.png" alt="image-20220731152023085"></p>
<ul>
<li><p>ShuffleBlockFetchIterator</p>
<ul>
<li>区分 local 和 remote 节省网络消耗</li>
<li>防止 OOM<ul>
<li>maxBytesInflight</li>
<li>maxReqsInFlight</li>
<li>maxBlocksInFlightPerAddress</li>
<li>maxReqSizeShuffleToMem</li>
<li>maxAttemptsOnNettyOOM</li>
</ul>
</li>
</ul>
</li>
<li><p>External Shuffle Service</p>
<p>ESS 作为一个存在于每个结点上的 agent 为所有 Shuffle Reader 提供服务，从而优化了 Spark 作业的资源利用率，MapTask 在运行结束后可以正常退出。</p>
</li>
</ul>
<p>**Shuffle 优化使用的技术 **</p>
<ul>
<li><p>Zero Copy</p>
<p>DMA(Direct Memory Access)：直接存储器读取，是指外部设备不通过 CPU 而直接与系统内存交换数据的接口技术。</p>
</li>
<li><p>Netty Zero Copy</p>
<ul>
<li>可堆外内存，避免 JVM 堆内存到堆外内存的数据拷贝。</li>
<li>CompositeByteBuf、Unpooled.wrappedBuffer、ByteBuf.slice，可以合并、包装、切分数组，避免发生内存拷贝。</li>
<li>Netty 使用 FileRegion 实现文件传输，FileRegion 底层封装了 FileChanel#trasferTo() 方法，可以将文件缓冲区的数据直接传输到目标 Channel，避免内核缓冲区和用户态缓冲区之间的数据拷贝。</li>
</ul>
</li>
</ul>
<p><strong>常见问题</strong></p>
<ul>
<li>数据存储在本地，没有备份；</li>
<li>IO 并发：大量 RPC 请求（M*R）</li>
<li>IO 吞吐：随机读、写放大（3X）</li>
<li>GC 频繁，影响 NodeManager</li>
</ul>
<p><strong>Shuffle 优化</strong></p>
<ul>
<li><p>避免 Shuffle</p>
<ul>
<li>使用 broadcast 替代 join</li>
</ul>
</li>
<li><p>使用可以 map-side 预聚合的算子</p>
</li>
<li><p>参数优化</p>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731154214778.png" alt="image-20220731154214778"></p>
</li>
<li><p>Shuffle 倾斜优化</p>
<ul>
<li><p>影响：作业运行时间变长、Task OMM 导致作业失败。</p>
</li>
<li><p>处理方法</p>
<ul>
<li><p>提高并行度（优点：简单；缺点：只缓解、不根治）</p>
</li>
<li><p>AQE</p>
<p>根据 Shuffle 文件统计数目自动检测倾斜数据，将那些倾斜的分区打散成更小的子分区，然后各自进行 join</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="4-Push-Shuffle"><a href="#4-Push-Shuffle" class="headerlink" title="4. Push Shuffle"></a>4. Push Shuffle</h2><blockquote>
<p>Avg IO size 太小，造成了大量的随机 IO，严重影响磁盘的吞吐；</p>
<p>M*R 次读请求，造成大量的网络连接，影响稳定性</p>
</blockquote>
<p><strong>Magnet 实现原理</strong></p>
<ul>
<li>Spark driver 组件，协调整个的 Shuffle 操作。</li>
<li>map 任务的 shuffle writer 过程完成后，增加了一个额外的操作 push-merge，将数据复制一份推送到远程 shuffle 服务器上。</li>
<li>magnet shuffle service 是一个强化版的 ESS。将隶属于同一个的 shuffle partition 的  block，会在远程传到 magnet 后被 merge 到一个文件中。</li>
<li>reduce 任务从 magnet shuffle service 接收合并好的 shuffle 数据。</li>
<li>bitmap：存储已 merger 的 mapper id，防止重复 merge。</li>
<li>position offset：如果本次 block 没有正常 merge，可以恢复到上一个 block 的位置。</li>
<li>currentMapId：表示当前正在 append 的 block，保证每个 mapper 的 block 能依次 append。</li>
</ul>
<p><strong>Magnet 可靠性</strong></p>
<ul>
<li>如果 Map tash 输出的 block 没有成功 Push 到  magnet 上，并且反复重试仍然失败，则 reduce task 直接从 ESS 上拉取原始 block 数据。</li>
<li>如果 magnet 上的 block 因为重复或者冲突等原因，没有正常完成 merge 的过程，则 reduce task 直接拉取未完成 merge 的 block</li>
<li>如果 reduce 拉去已经 merge 好的 block 失败，则会直接拉取 merge 前的原始 block</li>
<li>本质上，magnet 中维护了两份 shuffle 数据的副本</li>
</ul>
<p><strong>Cloud Shuffle Servie 思想</strong></p>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731160707875.png" alt="image-20220731160707875"></p>
<p>**<strong>Cloud shuffle Service 架构</strong></p>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731160801532.png" alt="image-20220731160801532"></p>
<p><strong>Cloud shuffle Service 写入流程</strong></p>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731160948086.png" alt="image-20220731160948086"></p>
<p><strong>Cloud Shuffle Service AQE</strong></p>
<p>一个 partition 会最终对应到多个 Epoch file，每个 RPoch 目前设置是 512 MB</p>
<p><img src="/blog/images/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/image-20220731161344573.png" alt="image-20220731161344573"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://the_ring.gitee.io/blog/2022/07/31/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/" data-id="cl6g3rxwf000mg4ut4rwx5ep3" data-title="大数据 Shuffle 原理与实践" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/big-data/" rel="tag">big data</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/shuffle/" rel="tag">shuffle</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-Hexo + GiteeGithub 搭建个人博客" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/blog/2022/07/30/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/" class="article-date">
  <time class="dt-published" datetime="2022-07-30T14:35:50.000Z" itemprop="datePublished">2022-07-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/blog/2022/07/30/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/">Hexo + Gitee/Github 搭建个人博客</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="一、-安装-Node-js-和-Git"><a href="#一、-安装-Node-js-和-Git" class="headerlink" title="一、 安装 Node.js 和 Git"></a>一、 安装 Node.js 和 Git</h2><p><a target="_blank" rel="noopener" href="https://nodejs.org/en/">Node.js</a></p>
<p><img src="/blog/images/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/image-20220730210351312.png" alt="image-20220730210351312"></p>
<p><img src="/blog/images/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/image-20220730210427462.png" alt="image-20220730210427462"></p>
<p><img src="/blog/images/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/image-20220730210530475.png" alt="image-20220730210530475"></p>
<p>自动安装完成即可</p>
<p>可以验证一下是否安装成功</p>
<p><img src="/blog/images/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/image-20220730210635122.png" alt="image-20220730210635122"></p>
<blockquote>
<p>已经安装过 Git，就不演示了</p>
</blockquote>
<h2 id="二、安装-Hexo"><a href="#二、安装-Hexo" class="headerlink" title="二、安装 Hexo"></a>二、安装 Hexo</h2><h3 id="1-安装-Hexo"><a href="#1-安装-Hexo" class="headerlink" title="1. 安装 Hexo"></a>1. 安装 Hexo</h3><p>修改使用淘宝链接进行安装</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g cnpm --registry=https://registry.npm.taobao.org</span><br></pre></td></tr></table></figure>

<p>开始安装</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cnpm install -g hexo-cli</span><br></pre></td></tr></table></figure>

<p>安装后验证</p>
<p><img src="/blog/images/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/image-20220730211707199.png" alt="image-20220730211707199"></p>
<h3 id="2-初始化"><a href="#2-初始化" class="headerlink" title="2. 初始化"></a>2. 初始化</h3><p>使用</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo init</span><br></pre></td></tr></table></figure>

<blockquote>
<p>先创建一个目录用来保存 blog，再在此目录下执行此命令</p>
</blockquote>
<p><img src="/blog/images/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/image-20220730212126969.png" alt="image-20220730212126969"></p>
<h3 id="3-启动"><a href="#3-启动" class="headerlink" title="3. 启动"></a>3. 启动</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo s</span><br></pre></td></tr></table></figure>

<p><img src="/blog/images/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/image-20220730212441470.png" alt="image-20220730212441470"></p>
<p>浏览器中使用 localhost:4000 即可访问</p>
<p><img src="/blog/images/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/image-20220730212408521.png" alt="image-20220730212408521"></p>
<h2 id="三、-部署到-Gitee-x2F-Github"><a href="#三、-部署到-Gitee-x2F-Github" class="headerlink" title="三、 部署到 Gitee&#x2F;Github"></a>三、 部署到 Gitee&#x2F;Github</h2><p>这里使用 Gitee 进行演示</p>
<h3 id="1-Gitee-上创建一个仓库"><a href="#1-Gitee-上创建一个仓库" class="headerlink" title="1. Gitee 上创建一个仓库"></a>1. Gitee 上创建一个仓库</h3><p><img src="/blog/images/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/image-20220730213227646.png" alt="image-20220730213227646"></p>
<h3 id="2-安装-Git-部署插件"><a href="#2-安装-Git-部署插件" class="headerlink" title="2. 安装 Git 部署插件"></a>2. 安装 Git 部署插件</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cnpm install --save hexo-deployer-git</span><br></pre></td></tr></table></figure>



<h3 id="3-修改配置"><a href="#3-修改配置" class="headerlink" title="3. 修改配置"></a>3. 修改配置</h3><p>打开安装目录的 <code>_config.yaml</code> 文件</p>
<p>添加以下内容</p>
<p><img src="/blog/images/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/image-20220730214249131.png" alt="image-20220730214249131"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://the_ring.gitee.io/blog/2022/07/30/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/" data-id="cl6g3rxw20003g4utf98q85ke" data-title="Hexo + Gitee/Github 搭建个人博客" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/gitee/" rel="tag">gitee</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/github/" rel="tag">github</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/hexo/" rel="tag">hexo</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-hello-world" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/blog/2022/07/30/hello-world/" class="article-date">
  <time class="dt-published" datetime="2022-07-30T13:18:21.150Z" itemprop="datePublished">2022-07-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/blog/2022/07/30/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://the_ring.gitee.io/blog/2022/07/30/hello-world/" data-id="cl6g3rxwe000lg4ut5nkd2rrx" data-title="Hello World" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/HDFS/" rel="tag">HDFS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/big-data/" rel="tag">big data</a></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/gitee/" rel="tag">gitee</a></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/github/" rel="tag">github</a></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/hexo/" rel="tag">hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/presto/" rel="tag">presto</a></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/shuffle/" rel="tag">shuffle</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/blog/tags/HDFS/" style="font-size: 15px;">HDFS</a> <a href="/blog/tags/big-data/" style="font-size: 20px;">big data</a> <a href="/blog/tags/gitee/" style="font-size: 10px;">gitee</a> <a href="/blog/tags/github/" style="font-size: 10px;">github</a> <a href="/blog/tags/hexo/" style="font-size: 10px;">hexo</a> <a href="/blog/tags/presto/" style="font-size: 10px;">presto</a> <a href="/blog/tags/shuffle/" style="font-size: 10px;">shuffle</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2022/08/">August 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2022/07/">July 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/blog/2022/08/05/HDFS%20%E9%AB%98%E5%8F%AF%E7%94%A8%E5%92%8C%E9%AB%98%E6%89%A9%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/">HDFS 高可用和高扩展机制分析</a>
          </li>
        
          <li>
            <a href="/blog/2022/08/05/HDFS%20%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/">HDFS 原理与应用</a>
          </li>
        
          <li>
            <a href="/blog/2022/08/03/Presto%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96%E4%BB%8B%E7%BB%8D/">Presto 架构原理与优化</a>
          </li>
        
          <li>
            <a href="/blog/2022/07/31/%E5%A4%A7%E6%95%B0%E6%8D%AE-Shuffle-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/">大数据 Shuffle 原理与实践</a>
          </li>
        
          <li>
            <a href="/blog/2022/07/30/Hexo%20+%20GiteeGithub%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/">Hexo + Gitee/Github 搭建个人博客</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/blog/" class="mobile-nav-link">Home</a>
  
    <a href="/blog/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/blog/js/jquery-3.4.1.min.js"></script>



  
<script src="/blog/fancybox/jquery.fancybox.min.js"></script>




<script src="/blog/js/script.js"></script>





  </div>
</body>
</html>